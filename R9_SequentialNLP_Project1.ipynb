{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "R9_SequentialNLP_Project1",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xT7MKZuMRaCg"
      },
      "source": [
        "# Sentiment Classification\n",
        "\n",
        "\n",
        "### Generate Word Embeddings and retrieve outputs of each layer with Keras based on Classification task\n",
        "\n",
        "Word embeddings are a type of word representation that allows words with similar meaning to have a similar representation.\n",
        "\n",
        "It is a distributed representation for text that is perhaps one of the key breakthroughs for the impressive performance of deep learning methods on challenging natural language processing problems.\n",
        "\n",
        "We willl use the imdb dataset to learn word embeddings as we train our dataset. This dataset contains 25,000 movie reviews from IMDB, labeled with sentiment (positive or negative). \n",
        "\n",
        "\n",
        "\n",
        "### Dataset\n",
        "\n",
        "`from keras.datasets import imdb`\n",
        "\n",
        "Dataset of 25,000 movies reviews from IMDB, labeled by sentiment (positive/negative). Reviews have been preprocessed, and each review is encoded as a sequence of word indexes (integers). For convenience, the words are indexed by their frequency in the dataset, meaning the for that has index 1 is the most frequent word. Use the first 20 words from each review to speed up training, using a max vocab size of 10,000.\n",
        "\n",
        "As a convention, \"0\" does not stand for a specific word, but instead is used to encode any unknown word.\n",
        "\n",
        "\n",
        "### Aim\n",
        "\n",
        "1. Import test and train data  \n",
        "2. Import the labels ( train and test) \n",
        "3. Get the word index and then Create key value pair for word and word_id. (12.5 points)\n",
        "4. Build a Sequential Model using Keras for Sentiment Classification task. (10 points)\n",
        "5. Report the Accuracy of the model. (5 points)  \n",
        "6. Retrive the output of each layer in keras for a given single test sample from the trained model you built. (2.5 points)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wq4RCyyPSYRp"
      },
      "source": [
        "#### Usage:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NGCtiXUhSWss",
        "outputId": "619b5064-cac5-409d-8585-1d2f45af61e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "# Import the IMDB Dataset\n",
        "\n",
        "from keras.datasets import imdb\n",
        "\n",
        "vocab_size = 10000 #vocab size,it is the most frequent words.\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size) "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-tIsykH4vqS",
        "colab_type": "code",
        "outputId": "ec082401-8123-4428-a3af-8a81e99a6f43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "# View sample Train and Test data\n",
        "\n",
        "x_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
              "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "       list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
              "       ...,\n",
              "       list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 2, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 2, 325, 725, 134, 2, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 2, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 2, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 2, 7750, 5, 4241, 18, 4, 8497, 2, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 2, 4, 3586, 2]),\n",
              "       list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
              "       list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 2, 21, 27, 9685, 6139, 5, 2, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 2, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 2, 2, 544, 5, 383, 1271, 848, 1468, 2, 497, 2, 8, 1597, 8778, 2, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fyDT0ufVU0z",
        "colab_type": "code",
        "outputId": "b552d92b-9bc7-4d25-dea7-453b0bab60ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "x_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 7944, 451, 202, 14, 6, 717]),\n",
              "       list([1, 14, 22, 3443, 6, 176, 7, 5063, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 2, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 2, 19, 861, 1074, 5, 1987, 2, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 2, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 2, 5, 4182, 30, 3127, 2, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 2, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077]),\n",
              "       list([1, 111, 748, 4368, 1133, 2, 2, 4, 87, 1551, 1262, 7, 31, 318, 9459, 7, 4, 498, 5076, 748, 63, 29, 5161, 220, 686, 2, 5, 17, 12, 575, 220, 2507, 17, 6, 185, 132, 2, 16, 53, 928, 11, 2, 74, 4, 438, 21, 27, 2, 589, 8, 22, 107, 2, 2, 997, 1638, 8, 35, 2076, 9019, 11, 22, 231, 54, 29, 1706, 29, 100, 2, 2425, 34, 2, 8738, 2, 5, 2, 98, 31, 2122, 33, 6, 58, 14, 3808, 1638, 8, 4, 365, 7, 2789, 3761, 356, 346, 4, 2, 1060, 63, 29, 93, 11, 5421, 11, 2, 33, 6, 58, 54, 1270, 431, 748, 7, 32, 2580, 16, 11, 94, 2, 10, 10, 4, 993, 2, 7, 4, 1766, 2634, 2164, 2, 8, 847, 8, 1450, 121, 31, 7, 27, 86, 2663, 2, 16, 6, 465, 993, 2006, 2, 573, 17, 2, 42, 4, 2, 37, 473, 6, 711, 6, 8869, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 3711, 53, 33, 2071, 1969, 37, 70, 1144, 4, 5940, 1409, 74, 476, 37, 62, 91, 1329, 169, 4, 1330, 2, 146, 655, 2212, 5, 258, 12, 184, 2, 546, 5, 849, 2, 7, 4, 22, 1436, 18, 631, 1386, 797, 7, 4, 8712, 71, 348, 425, 4320, 1061, 19, 2, 5, 2, 11, 661, 8, 339, 2, 4, 2455, 2, 7, 4, 1962, 10, 10, 263, 787, 9, 270, 11, 6, 9466, 4, 2, 2, 121, 4, 5437, 26, 4434, 19, 68, 1372, 5, 28, 446, 6, 318, 7149, 8, 67, 51, 36, 70, 81, 8, 4392, 2294, 36, 1197, 8, 2, 2, 18, 6, 711, 4, 9909, 26, 2, 1125, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 7489, 6175, 168, 1239, 5189, 137, 2, 18, 27, 173, 9, 2399, 17, 6, 2, 428, 2, 232, 11, 4, 8014, 37, 272, 40, 2708, 247, 30, 656, 6, 2, 54, 2, 3292, 98, 6, 2840, 40, 558, 37, 6093, 98, 4, 2, 1197, 15, 14, 9, 57, 4893, 5, 4659, 6, 275, 711, 7937, 2, 3292, 98, 6, 2, 10, 10, 6639, 19, 14, 2, 267, 162, 711, 37, 5900, 752, 98, 4, 2, 2378, 90, 19, 6, 2, 7, 2, 1810, 2, 4, 4770, 3183, 930, 8, 508, 90, 4, 1317, 8, 4, 2, 17, 2, 3965, 1853, 4, 1494, 8, 4468, 189, 4, 2, 6287, 5774, 4, 4770, 5, 95, 271, 23, 6, 7742, 6063, 2, 5437, 33, 1526, 6, 425, 3155, 2, 4535, 1636, 7, 4, 4669, 2, 469, 4, 4552, 54, 4, 150, 5664, 2, 280, 53, 2, 2, 18, 339, 29, 1978, 27, 7885, 5, 2, 68, 1830, 19, 6571, 2, 4, 1515, 7, 263, 65, 2132, 34, 6, 5680, 7489, 43, 159, 29, 9, 4706, 9, 387, 73, 195, 584, 10, 10, 1069, 4, 58, 810, 54, 14, 6078, 117, 22, 16, 93, 5, 1069, 4, 192, 15, 12, 16, 93, 34, 6, 1766, 2, 33, 4, 5673, 7, 15, 2, 9252, 3286, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 2, 44, 148, 687, 2, 203, 42, 203, 24, 28, 69, 2, 6676, 11, 330, 54, 29, 93, 2, 21, 845, 2, 27, 1099, 7, 819, 4, 22, 1407, 17, 6, 2, 787, 7, 2460, 2, 2, 100, 30, 4, 3737, 3617, 3169, 2321, 42, 1898, 11, 4, 3814, 42, 101, 704, 7, 101, 999, 15, 1625, 94, 2926, 180, 5, 9, 9101, 34, 2, 45, 6, 1429, 22, 60, 6, 1220, 31, 11, 94, 6408, 96, 21, 94, 749, 9, 57, 975]),\n",
              "       ...,\n",
              "       list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 2, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 2, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
              "       list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 2, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
              "       list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 2, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 2, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 2, 21, 4, 7298, 2, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 2, 2, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 2, 5698, 3406, 718, 2, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 2, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 2, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WHAK4O05tyn",
        "colab_type": "code",
        "outputId": "0f951fee-8850-48a7-a713-fac99858731a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7eFOGpWAgua",
        "colab_type": "code",
        "outputId": "4354542e-8ac2-4e50-c87e-094b7e84c727",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Dictiionary for Word ID vs Word\n",
        "\n",
        "word_to_id = imdb.get_word_index()\n",
        "word_to_id = {k:v for k,v in word_to_id.items()}\n",
        "id_to_word = {value:key for key,value in word_to_id.items()}\n",
        "id_to_word"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{34701: 'fawn',\n",
              " 52006: 'tsukino',\n",
              " 52007: 'nunnery',\n",
              " 16816: 'sonja',\n",
              " 63951: 'vani',\n",
              " 1408: 'woods',\n",
              " 16115: 'spiders',\n",
              " 2345: 'hanging',\n",
              " 2289: 'woody',\n",
              " 52008: 'trawling',\n",
              " 52009: \"hold's\",\n",
              " 11307: 'comically',\n",
              " 40830: 'localized',\n",
              " 30568: 'disobeying',\n",
              " 52010: \"'royale\",\n",
              " 40831: \"harpo's\",\n",
              " 52011: 'canet',\n",
              " 19313: 'aileen',\n",
              " 52012: 'acurately',\n",
              " 52013: \"diplomat's\",\n",
              " 25242: 'rickman',\n",
              " 6746: 'arranged',\n",
              " 52014: 'rumbustious',\n",
              " 52015: 'familiarness',\n",
              " 52016: \"spider'\",\n",
              " 68804: 'hahahah',\n",
              " 52017: \"wood'\",\n",
              " 40833: 'transvestism',\n",
              " 34702: \"hangin'\",\n",
              " 2338: 'bringing',\n",
              " 40834: 'seamier',\n",
              " 34703: 'wooded',\n",
              " 52018: 'bravora',\n",
              " 16817: 'grueling',\n",
              " 1636: 'wooden',\n",
              " 16818: 'wednesday',\n",
              " 52019: \"'prix\",\n",
              " 34704: 'altagracia',\n",
              " 52020: 'circuitry',\n",
              " 11585: 'crotch',\n",
              " 57766: 'busybody',\n",
              " 52021: \"tart'n'tangy\",\n",
              " 14129: 'burgade',\n",
              " 52023: 'thrace',\n",
              " 11038: \"tom's\",\n",
              " 52025: 'snuggles',\n",
              " 29114: 'francesco',\n",
              " 52027: 'complainers',\n",
              " 52125: 'templarios',\n",
              " 40835: '272',\n",
              " 52028: '273',\n",
              " 52130: 'zaniacs',\n",
              " 34706: '275',\n",
              " 27631: 'consenting',\n",
              " 40836: 'snuggled',\n",
              " 15492: 'inanimate',\n",
              " 52030: 'uality',\n",
              " 11926: 'bronte',\n",
              " 4010: 'errors',\n",
              " 3230: 'dialogs',\n",
              " 52031: \"yomada's\",\n",
              " 34707: \"madman's\",\n",
              " 30585: 'dialoge',\n",
              " 52033: 'usenet',\n",
              " 40837: 'videodrome',\n",
              " 26338: \"kid'\",\n",
              " 52034: 'pawed',\n",
              " 30569: \"'girlfriend'\",\n",
              " 52035: \"'pleasure\",\n",
              " 52036: \"'reloaded'\",\n",
              " 40839: \"kazakos'\",\n",
              " 52037: 'rocque',\n",
              " 52038: 'mailings',\n",
              " 11927: 'brainwashed',\n",
              " 16819: 'mcanally',\n",
              " 52039: \"tom''\",\n",
              " 25243: 'kurupt',\n",
              " 21905: 'affiliated',\n",
              " 52040: 'babaganoosh',\n",
              " 40840: \"noe's\",\n",
              " 40841: 'quart',\n",
              " 359: 'kids',\n",
              " 5034: 'uplifting',\n",
              " 7093: 'controversy',\n",
              " 21906: 'kida',\n",
              " 23379: 'kidd',\n",
              " 52041: \"error'\",\n",
              " 52042: 'neurologist',\n",
              " 18510: 'spotty',\n",
              " 30570: 'cobblers',\n",
              " 9878: 'projection',\n",
              " 40842: 'fastforwarding',\n",
              " 52043: 'sters',\n",
              " 52044: \"eggar's\",\n",
              " 52045: 'etherything',\n",
              " 40843: 'gateshead',\n",
              " 34708: 'airball',\n",
              " 25244: 'unsinkable',\n",
              " 7180: 'stern',\n",
              " 52046: \"cervi's\",\n",
              " 40844: 'dnd',\n",
              " 11586: 'dna',\n",
              " 20598: 'insecurity',\n",
              " 52047: \"'reboot'\",\n",
              " 11037: 'trelkovsky',\n",
              " 52048: 'jaekel',\n",
              " 52049: 'sidebars',\n",
              " 52050: \"sforza's\",\n",
              " 17633: 'distortions',\n",
              " 52051: 'mutinies',\n",
              " 30602: 'sermons',\n",
              " 40846: '7ft',\n",
              " 52052: 'boobage',\n",
              " 52053: \"o'bannon's\",\n",
              " 23380: 'populations',\n",
              " 52054: 'chulak',\n",
              " 27633: 'mesmerize',\n",
              " 52055: 'quinnell',\n",
              " 10307: 'yahoo',\n",
              " 52057: 'meteorologist',\n",
              " 42577: 'beswick',\n",
              " 15493: 'boorman',\n",
              " 40847: 'voicework',\n",
              " 52058: \"ster'\",\n",
              " 22922: 'blustering',\n",
              " 52059: 'hj',\n",
              " 27634: 'intake',\n",
              " 5621: 'morally',\n",
              " 40849: 'jumbling',\n",
              " 52060: 'bowersock',\n",
              " 52061: \"'porky's'\",\n",
              " 16821: 'gershon',\n",
              " 40850: 'ludicrosity',\n",
              " 52062: 'coprophilia',\n",
              " 40851: 'expressively',\n",
              " 19500: \"india's\",\n",
              " 34710: \"post's\",\n",
              " 52063: 'wana',\n",
              " 5283: 'wang',\n",
              " 30571: 'wand',\n",
              " 25245: 'wane',\n",
              " 52321: 'edgeways',\n",
              " 34711: 'titanium',\n",
              " 40852: 'pinta',\n",
              " 178: 'want',\n",
              " 30572: 'pinto',\n",
              " 52065: 'whoopdedoodles',\n",
              " 21908: 'tchaikovsky',\n",
              " 2103: 'travel',\n",
              " 52066: \"'victory'\",\n",
              " 11928: 'copious',\n",
              " 22433: 'gouge',\n",
              " 52067: \"chapters'\",\n",
              " 6702: 'barbra',\n",
              " 30573: 'uselessness',\n",
              " 52068: \"wan'\",\n",
              " 27635: 'assimilated',\n",
              " 16116: 'petiot',\n",
              " 52069: 'most\\x85and',\n",
              " 3930: 'dinosaurs',\n",
              " 352: 'wrong',\n",
              " 52070: 'seda',\n",
              " 52071: 'stollen',\n",
              " 34712: 'sentencing',\n",
              " 40853: 'ouroboros',\n",
              " 40854: 'assimilates',\n",
              " 40855: 'colorfully',\n",
              " 27636: 'glenne',\n",
              " 52072: 'dongen',\n",
              " 4760: 'subplots',\n",
              " 52073: 'kiloton',\n",
              " 23381: 'chandon',\n",
              " 34713: \"effect'\",\n",
              " 27637: 'snugly',\n",
              " 40856: 'kuei',\n",
              " 9092: 'welcomed',\n",
              " 30071: 'dishonor',\n",
              " 52075: 'concurrence',\n",
              " 23382: 'stoicism',\n",
              " 14896: \"guys'\",\n",
              " 52077: \"beroemd'\",\n",
              " 6703: 'butcher',\n",
              " 40857: \"melfi's\",\n",
              " 30623: 'aargh',\n",
              " 20599: 'playhouse',\n",
              " 11308: 'wickedly',\n",
              " 1180: 'fit',\n",
              " 52078: 'labratory',\n",
              " 40859: 'lifeline',\n",
              " 1927: 'screaming',\n",
              " 4287: 'fix',\n",
              " 52079: 'cineliterate',\n",
              " 52080: 'fic',\n",
              " 52081: 'fia',\n",
              " 34714: 'fig',\n",
              " 52082: 'fmvs',\n",
              " 52083: 'fie',\n",
              " 52084: 'reentered',\n",
              " 30574: 'fin',\n",
              " 52085: 'doctresses',\n",
              " 52086: 'fil',\n",
              " 12606: 'zucker',\n",
              " 31931: 'ached',\n",
              " 52088: 'counsil',\n",
              " 52089: 'paterfamilias',\n",
              " 13885: 'songwriter',\n",
              " 34715: 'shivam',\n",
              " 9654: 'hurting',\n",
              " 299: 'effects',\n",
              " 52090: 'slauther',\n",
              " 52091: \"'flame'\",\n",
              " 52092: 'sommerset',\n",
              " 52093: 'interwhined',\n",
              " 27638: 'whacking',\n",
              " 52094: 'bartok',\n",
              " 8775: 'barton',\n",
              " 21909: 'frewer',\n",
              " 52095: \"fi'\",\n",
              " 6192: 'ingrid',\n",
              " 30575: 'stribor',\n",
              " 52096: 'approporiately',\n",
              " 52097: 'wobblyhand',\n",
              " 52098: 'tantalisingly',\n",
              " 52099: 'ankylosaurus',\n",
              " 17634: 'parasites',\n",
              " 52100: 'childen',\n",
              " 52101: \"jenkins'\",\n",
              " 52102: 'metafiction',\n",
              " 17635: 'golem',\n",
              " 40860: 'indiscretion',\n",
              " 23383: \"reeves'\",\n",
              " 57781: \"inamorata's\",\n",
              " 52104: 'brittannica',\n",
              " 7916: 'adapt',\n",
              " 30576: \"russo's\",\n",
              " 48246: 'guitarists',\n",
              " 10553: 'abbott',\n",
              " 40861: 'abbots',\n",
              " 17649: 'lanisha',\n",
              " 40863: 'magickal',\n",
              " 52105: 'mattter',\n",
              " 52106: \"'willy\",\n",
              " 34716: 'pumpkins',\n",
              " 52107: 'stuntpeople',\n",
              " 30577: 'estimate',\n",
              " 40864: 'ugghhh',\n",
              " 11309: 'gameplay',\n",
              " 52108: \"wern't\",\n",
              " 40865: \"n'sync\",\n",
              " 16117: 'sickeningly',\n",
              " 40866: 'chiara',\n",
              " 4011: 'disturbed',\n",
              " 40867: 'portmanteau',\n",
              " 52109: 'ineffectively',\n",
              " 82143: \"duchonvey's\",\n",
              " 37519: \"nasty'\",\n",
              " 1285: 'purpose',\n",
              " 52112: 'lazers',\n",
              " 28105: 'lightened',\n",
              " 52113: 'kaliganj',\n",
              " 52114: 'popularism',\n",
              " 18511: \"damme's\",\n",
              " 30578: 'stylistics',\n",
              " 52115: 'mindgaming',\n",
              " 46449: 'spoilerish',\n",
              " 52117: \"'corny'\",\n",
              " 34718: 'boerner',\n",
              " 6792: 'olds',\n",
              " 52118: 'bakelite',\n",
              " 27639: 'renovated',\n",
              " 27640: 'forrester',\n",
              " 52119: \"lumiere's\",\n",
              " 52024: 'gaskets',\n",
              " 884: 'needed',\n",
              " 34719: 'smight',\n",
              " 1297: 'master',\n",
              " 25905: \"edie's\",\n",
              " 40868: 'seeber',\n",
              " 52120: 'hiya',\n",
              " 52121: 'fuzziness',\n",
              " 14897: 'genesis',\n",
              " 12607: 'rewards',\n",
              " 30579: 'enthrall',\n",
              " 40869: \"'about\",\n",
              " 52122: \"recollection's\",\n",
              " 11039: 'mutilated',\n",
              " 52123: 'fatherlands',\n",
              " 52124: \"fischer's\",\n",
              " 5399: 'positively',\n",
              " 34705: '270',\n",
              " 34720: 'ahmed',\n",
              " 9836: 'zatoichi',\n",
              " 13886: 'bannister',\n",
              " 52127: 'anniversaries',\n",
              " 30580: \"helm's\",\n",
              " 52128: \"'work'\",\n",
              " 34721: 'exclaimed',\n",
              " 52129: \"'unfunny'\",\n",
              " 52029: '274',\n",
              " 544: 'feeling',\n",
              " 52131: \"wanda's\",\n",
              " 33266: 'dolan',\n",
              " 52133: '278',\n",
              " 52134: 'peacoat',\n",
              " 40870: 'brawny',\n",
              " 40871: 'mishra',\n",
              " 40872: 'worlders',\n",
              " 52135: 'protags',\n",
              " 52136: 'skullcap',\n",
              " 57596: 'dastagir',\n",
              " 5622: 'affairs',\n",
              " 7799: 'wholesome',\n",
              " 52137: 'hymen',\n",
              " 25246: 'paramedics',\n",
              " 52138: 'unpersons',\n",
              " 52139: 'heavyarms',\n",
              " 52140: 'affaire',\n",
              " 52141: 'coulisses',\n",
              " 40873: 'hymer',\n",
              " 52142: 'kremlin',\n",
              " 30581: 'shipments',\n",
              " 52143: 'pixilated',\n",
              " 30582: \"'00s\",\n",
              " 18512: 'diminishing',\n",
              " 1357: 'cinematic',\n",
              " 14898: 'resonates',\n",
              " 40874: 'simplify',\n",
              " 40875: \"nature'\",\n",
              " 40876: 'temptresses',\n",
              " 16822: 'reverence',\n",
              " 19502: 'resonated',\n",
              " 34722: 'dailey',\n",
              " 52144: '2\\x85',\n",
              " 27641: 'treize',\n",
              " 52145: 'majo',\n",
              " 21910: 'kiya',\n",
              " 52146: 'woolnough',\n",
              " 39797: 'thanatos',\n",
              " 35731: 'sandoval',\n",
              " 40879: 'dorama',\n",
              " 52147: \"o'shaughnessy\",\n",
              " 4988: 'tech',\n",
              " 32018: 'fugitives',\n",
              " 30583: 'teck',\n",
              " 76125: \"'e'\",\n",
              " 40881: 'doesn’t',\n",
              " 52149: 'purged',\n",
              " 657: 'saying',\n",
              " 41095: \"martians'\",\n",
              " 23418: 'norliss',\n",
              " 27642: 'dickey',\n",
              " 52152: 'dicker',\n",
              " 52153: \"'sependipity\",\n",
              " 8422: 'padded',\n",
              " 57792: 'ordell',\n",
              " 40882: \"sturges'\",\n",
              " 52154: 'independentcritics',\n",
              " 5745: 'tempted',\n",
              " 34724: \"atkinson's\",\n",
              " 25247: 'hounded',\n",
              " 52155: 'apace',\n",
              " 15494: 'clicked',\n",
              " 30584: \"'humor'\",\n",
              " 17177: \"martino's\",\n",
              " 52156: \"'supporting\",\n",
              " 52032: 'warmongering',\n",
              " 34725: \"zemeckis's\",\n",
              " 21911: 'lube',\n",
              " 52157: 'shocky',\n",
              " 7476: 'plate',\n",
              " 40883: 'plata',\n",
              " 40884: 'sturgess',\n",
              " 40885: \"nerds'\",\n",
              " 20600: 'plato',\n",
              " 34726: 'plath',\n",
              " 40886: 'platt',\n",
              " 52159: 'mcnab',\n",
              " 27643: 'clumsiness',\n",
              " 3899: 'altogether',\n",
              " 42584: 'massacring',\n",
              " 52160: 'bicenntinial',\n",
              " 40887: 'skaal',\n",
              " 14360: 'droning',\n",
              " 8776: 'lds',\n",
              " 21912: 'jaguar',\n",
              " 34727: \"cale's\",\n",
              " 1777: 'nicely',\n",
              " 4588: 'mummy',\n",
              " 18513: \"lot's\",\n",
              " 10086: 'patch',\n",
              " 50202: 'kerkhof',\n",
              " 52161: \"leader's\",\n",
              " 27644: \"'movie\",\n",
              " 52162: 'uncomfirmed',\n",
              " 40888: 'heirloom',\n",
              " 47360: 'wrangle',\n",
              " 52163: 'emotion\\x85',\n",
              " 52164: \"'stargate'\",\n",
              " 40889: 'pinoy',\n",
              " 40890: 'conchatta',\n",
              " 41128: 'broeke',\n",
              " 40891: 'advisedly',\n",
              " 17636: \"barker's\",\n",
              " 52166: 'descours',\n",
              " 772: 'lots',\n",
              " 9259: 'lotr',\n",
              " 9879: 'irs',\n",
              " 52167: 'lott',\n",
              " 40892: 'xvi',\n",
              " 34728: 'irk',\n",
              " 52168: 'irl',\n",
              " 6887: 'ira',\n",
              " 21913: 'belzer',\n",
              " 52169: 'irc',\n",
              " 27645: 'ire',\n",
              " 40893: 'requisites',\n",
              " 7693: 'discipline',\n",
              " 52961: 'lyoko',\n",
              " 11310: 'extend',\n",
              " 873: 'nature',\n",
              " 52170: \"'dickie'\",\n",
              " 40894: 'optimist',\n",
              " 30586: 'lapping',\n",
              " 3900: 'superficial',\n",
              " 52171: 'vestment',\n",
              " 2823: 'extent',\n",
              " 52172: 'tendons',\n",
              " 52173: \"heller's\",\n",
              " 52174: 'quagmires',\n",
              " 52175: 'miyako',\n",
              " 20601: 'moocow',\n",
              " 52176: \"coles'\",\n",
              " 40895: 'lookit',\n",
              " 52177: 'ravenously',\n",
              " 40896: 'levitating',\n",
              " 52178: 'perfunctorily',\n",
              " 30587: 'lookin',\n",
              " 40898: \"lot'\",\n",
              " 52179: 'lookie',\n",
              " 34870: 'fearlessly',\n",
              " 52181: 'libyan',\n",
              " 40899: 'fondles',\n",
              " 35714: 'gopher',\n",
              " 40901: 'wearying',\n",
              " 52182: \"nz's\",\n",
              " 27646: 'minuses',\n",
              " 52183: 'puposelessly',\n",
              " 52184: 'shandling',\n",
              " 31268: 'decapitates',\n",
              " 11929: 'humming',\n",
              " 40902: \"'nother\",\n",
              " 21914: 'smackdown',\n",
              " 30588: 'underdone',\n",
              " 40903: 'frf',\n",
              " 52185: 'triviality',\n",
              " 25248: 'fro',\n",
              " 8777: 'bothers',\n",
              " 52186: \"'kensington\",\n",
              " 73: 'much',\n",
              " 34730: 'muco',\n",
              " 22615: 'wiseguy',\n",
              " 27648: \"richie's\",\n",
              " 40904: 'tonino',\n",
              " 52187: 'unleavened',\n",
              " 11587: 'fry',\n",
              " 40905: \"'tv'\",\n",
              " 40906: 'toning',\n",
              " 14361: 'obese',\n",
              " 30589: 'sensationalized',\n",
              " 40907: 'spiv',\n",
              " 6259: 'spit',\n",
              " 7364: 'arkin',\n",
              " 21915: 'charleton',\n",
              " 16823: 'jeon',\n",
              " 21916: 'boardroom',\n",
              " 4989: 'doubts',\n",
              " 3084: 'spin',\n",
              " 53083: 'hepo',\n",
              " 27649: 'wildcat',\n",
              " 10584: 'venoms',\n",
              " 52191: 'misconstrues',\n",
              " 18514: 'mesmerising',\n",
              " 40908: 'misconstrued',\n",
              " 52192: 'rescinds',\n",
              " 52193: 'prostrate',\n",
              " 40909: 'majid',\n",
              " 16479: 'climbed',\n",
              " 34731: 'canoeing',\n",
              " 52195: 'majin',\n",
              " 57804: 'animie',\n",
              " 40910: 'sylke',\n",
              " 14899: 'conditioned',\n",
              " 40911: 'waddell',\n",
              " 52196: '3\\x85',\n",
              " 41188: 'hyperdrive',\n",
              " 34732: 'conditioner',\n",
              " 53153: 'bricklayer',\n",
              " 2576: 'hong',\n",
              " 52198: 'memoriam',\n",
              " 30592: 'inventively',\n",
              " 25249: \"levant's\",\n",
              " 20638: 'portobello',\n",
              " 52200: 'remand',\n",
              " 19504: 'mummified',\n",
              " 27650: 'honk',\n",
              " 19505: 'spews',\n",
              " 40912: 'visitations',\n",
              " 52201: 'mummifies',\n",
              " 25250: 'cavanaugh',\n",
              " 23385: 'zeon',\n",
              " 40913: \"jungle's\",\n",
              " 34733: 'viertel',\n",
              " 27651: 'frenchmen',\n",
              " 52202: 'torpedoes',\n",
              " 52203: 'schlessinger',\n",
              " 34734: 'torpedoed',\n",
              " 69876: 'blister',\n",
              " 52204: 'cinefest',\n",
              " 34735: 'furlough',\n",
              " 52205: 'mainsequence',\n",
              " 40914: 'mentors',\n",
              " 9094: 'academic',\n",
              " 20602: 'stillness',\n",
              " 40915: 'academia',\n",
              " 52206: 'lonelier',\n",
              " 52207: 'nibby',\n",
              " 52208: \"losers'\",\n",
              " 40916: 'cineastes',\n",
              " 4449: 'corporate',\n",
              " 40917: 'massaging',\n",
              " 30593: 'bellow',\n",
              " 19506: 'absurdities',\n",
              " 53241: 'expetations',\n",
              " 40918: 'nyfiken',\n",
              " 75638: 'mehras',\n",
              " 52209: 'lasse',\n",
              " 52210: 'visability',\n",
              " 33946: 'militarily',\n",
              " 52211: \"elder'\",\n",
              " 19023: 'gainsbourg',\n",
              " 20603: 'hah',\n",
              " 13420: 'hai',\n",
              " 34736: 'haj',\n",
              " 25251: 'hak',\n",
              " 4311: 'hal',\n",
              " 4892: 'ham',\n",
              " 53259: 'duffer',\n",
              " 52213: 'haa',\n",
              " 66: 'had',\n",
              " 11930: 'advancement',\n",
              " 16825: 'hag',\n",
              " 25252: \"hand'\",\n",
              " 13421: 'hay',\n",
              " 20604: 'mcnamara',\n",
              " 52214: \"mozart's\",\n",
              " 30731: 'duffel',\n",
              " 30594: 'haq',\n",
              " 13887: 'har',\n",
              " 44: 'has',\n",
              " 2401: 'hat',\n",
              " 40919: 'hav',\n",
              " 30595: 'haw',\n",
              " 52215: 'figtings',\n",
              " 15495: 'elders',\n",
              " 52216: 'underpanted',\n",
              " 52217: 'pninson',\n",
              " 27652: 'unequivocally',\n",
              " 23673: \"barbara's\",\n",
              " 52219: \"bello'\",\n",
              " 12997: 'indicative',\n",
              " 40920: 'yawnfest',\n",
              " 52220: 'hexploitation',\n",
              " 52221: \"loder's\",\n",
              " 27653: 'sleuthing',\n",
              " 32622: \"justin's\",\n",
              " 52222: \"'ball\",\n",
              " 52223: \"'summer\",\n",
              " 34935: \"'demons'\",\n",
              " 52225: \"mormon's\",\n",
              " 34737: \"laughton's\",\n",
              " 52226: 'debell',\n",
              " 39724: 'shipyard',\n",
              " 30597: 'unabashedly',\n",
              " 40401: 'disks',\n",
              " 2290: 'crowd',\n",
              " 10087: 'crowe',\n",
              " 56434: \"vancouver's\",\n",
              " 34738: 'mosques',\n",
              " 6627: 'crown',\n",
              " 52227: 'culpas',\n",
              " 27654: 'crows',\n",
              " 53344: 'surrell',\n",
              " 52229: 'flowless',\n",
              " 52230: 'sheirk',\n",
              " 40923: \"'three\",\n",
              " 52231: \"peterson'\",\n",
              " 52232: 'ooverall',\n",
              " 40924: 'perchance',\n",
              " 1321: 'bottom',\n",
              " 53363: 'chabert',\n",
              " 52233: 'sneha',\n",
              " 13888: 'inhuman',\n",
              " 52234: 'ichii',\n",
              " 52235: 'ursla',\n",
              " 30598: 'completly',\n",
              " 40925: 'moviedom',\n",
              " 52236: 'raddick',\n",
              " 51995: 'brundage',\n",
              " 40926: 'brigades',\n",
              " 1181: 'starring',\n",
              " 52237: \"'goal'\",\n",
              " 52238: 'caskets',\n",
              " 52239: 'willcock',\n",
              " 52240: \"threesome's\",\n",
              " 52241: \"mosque'\",\n",
              " 52242: \"cover's\",\n",
              " 17637: 'spaceships',\n",
              " 40927: 'anomalous',\n",
              " 27655: 'ptsd',\n",
              " 52243: 'shirdan',\n",
              " 21962: 'obscenity',\n",
              " 30599: 'lemmings',\n",
              " 30600: 'duccio',\n",
              " 52244: \"levene's\",\n",
              " 52245: \"'gorby'\",\n",
              " 25255: \"teenager's\",\n",
              " 5340: 'marshall',\n",
              " 9095: 'honeymoon',\n",
              " 3231: 'shoots',\n",
              " 12258: 'despised',\n",
              " 52246: 'okabasho',\n",
              " 8289: 'fabric',\n",
              " 18515: 'cannavale',\n",
              " 3537: 'raped',\n",
              " 52247: \"tutt's\",\n",
              " 17638: 'grasping',\n",
              " 18516: 'despises',\n",
              " 40928: \"thief's\",\n",
              " 8926: 'rapes',\n",
              " 52248: 'raper',\n",
              " 27656: \"eyre'\",\n",
              " 52249: 'walchek',\n",
              " 23386: \"elmo's\",\n",
              " 40929: 'perfumes',\n",
              " 21918: 'spurting',\n",
              " 52250: \"exposition'\\x85\",\n",
              " 52251: 'denoting',\n",
              " 34740: 'thesaurus',\n",
              " 40930: \"shoot'\",\n",
              " 49759: 'bonejack',\n",
              " 52253: 'simpsonian',\n",
              " 30601: 'hebetude',\n",
              " 34741: \"hallow's\",\n",
              " 52254: 'desperation\\x85',\n",
              " 34742: 'incinerator',\n",
              " 10308: 'congratulations',\n",
              " 52255: 'humbled',\n",
              " 5924: \"else's\",\n",
              " 40845: 'trelkovski',\n",
              " 52256: \"rape'\",\n",
              " 59386: \"'chapters'\",\n",
              " 52257: '1600s',\n",
              " 7253: 'martian',\n",
              " 25256: 'nicest',\n",
              " 52259: 'eyred',\n",
              " 9457: 'passenger',\n",
              " 6041: 'disgrace',\n",
              " 52260: 'moderne',\n",
              " 5120: 'barrymore',\n",
              " 52261: 'yankovich',\n",
              " 40931: 'moderns',\n",
              " 52262: 'studliest',\n",
              " 52263: 'bedsheet',\n",
              " 14900: 'decapitation',\n",
              " 52264: 'slurring',\n",
              " 52265: \"'nunsploitation'\",\n",
              " 34743: \"'character'\",\n",
              " 9880: 'cambodia',\n",
              " 52266: 'rebelious',\n",
              " 27657: 'pasadena',\n",
              " 40932: 'crowne',\n",
              " 52267: \"'bedchamber\",\n",
              " 52268: 'conjectural',\n",
              " 52269: 'appologize',\n",
              " 52270: 'halfassing',\n",
              " 57816: 'paycheque',\n",
              " 20606: 'palms',\n",
              " 52271: \"'islands\",\n",
              " 40933: 'hawked',\n",
              " 21919: 'palme',\n",
              " 40934: 'conservatively',\n",
              " 64007: 'larp',\n",
              " 5558: 'palma',\n",
              " 21920: 'smelling',\n",
              " 12998: 'aragorn',\n",
              " 52272: 'hawker',\n",
              " 52273: 'hawkes',\n",
              " 3975: 'explosions',\n",
              " 8059: 'loren',\n",
              " 52274: \"pyle's\",\n",
              " 6704: 'shootout',\n",
              " 18517: \"mike's\",\n",
              " 52275: \"driscoll's\",\n",
              " 40935: 'cogsworth',\n",
              " 52276: \"britian's\",\n",
              " 34744: 'childs',\n",
              " 52277: \"portrait's\",\n",
              " 3626: 'chain',\n",
              " 2497: 'whoever',\n",
              " 52278: 'puttered',\n",
              " 52279: 'childe',\n",
              " 52280: 'maywether',\n",
              " 3036: 'chair',\n",
              " 52281: \"rance's\",\n",
              " 34745: 'machu',\n",
              " 4517: 'ballet',\n",
              " 34746: 'grapples',\n",
              " 76152: 'summerize',\n",
              " 30603: 'freelance',\n",
              " 52283: \"andrea's\",\n",
              " 52284: '\\x91very',\n",
              " 45879: 'coolidge',\n",
              " 18518: 'mache',\n",
              " 52285: 'balled',\n",
              " 40937: 'grappled',\n",
              " 18519: 'macha',\n",
              " 21921: 'underlining',\n",
              " 5623: 'macho',\n",
              " 19507: 'oversight',\n",
              " 25257: 'machi',\n",
              " 11311: 'verbally',\n",
              " 21922: 'tenacious',\n",
              " 40938: 'windshields',\n",
              " 18557: 'paychecks',\n",
              " 3396: 'jerk',\n",
              " 11931: \"good'\",\n",
              " 34748: 'prancer',\n",
              " 21923: 'prances',\n",
              " 52286: 'olympus',\n",
              " 21924: 'lark',\n",
              " 10785: 'embark',\n",
              " 7365: 'gloomy',\n",
              " 52287: 'jehaan',\n",
              " 52288: 'turaqui',\n",
              " 20607: \"child'\",\n",
              " 2894: 'locked',\n",
              " 52289: 'pranced',\n",
              " 2588: 'exact',\n",
              " 52290: 'unattuned',\n",
              " 783: 'minute',\n",
              " 16118: 'skewed',\n",
              " 40940: 'hodgins',\n",
              " 34749: 'skewer',\n",
              " 52291: 'think\\x85',\n",
              " 38765: 'rosenstein',\n",
              " 52292: 'helmit',\n",
              " 34750: 'wrestlemanias',\n",
              " 16826: 'hindered',\n",
              " 30604: \"martha's\",\n",
              " 52293: 'cheree',\n",
              " 52294: \"pluckin'\",\n",
              " 40941: 'ogles',\n",
              " 11932: 'heavyweight',\n",
              " 82190: 'aada',\n",
              " 11312: 'chopping',\n",
              " 61534: 'strongboy',\n",
              " 41342: 'hegemonic',\n",
              " 40942: 'adorns',\n",
              " 41346: 'xxth',\n",
              " 34751: 'nobuhiro',\n",
              " 52298: 'capitães',\n",
              " 52299: 'kavogianni',\n",
              " 13422: 'antwerp',\n",
              " 6538: 'celebrated',\n",
              " 52300: 'roarke',\n",
              " 40943: 'baggins',\n",
              " 31270: 'cheeseburgers',\n",
              " 52301: 'matras',\n",
              " 52302: \"nineties'\",\n",
              " 52303: \"'craig'\",\n",
              " 12999: 'celebrates',\n",
              " 3383: 'unintentionally',\n",
              " 14362: 'drafted',\n",
              " 52304: 'climby',\n",
              " 52305: '303',\n",
              " 18520: 'oldies',\n",
              " 9096: 'climbs',\n",
              " 9655: 'honour',\n",
              " 34752: 'plucking',\n",
              " 30074: '305',\n",
              " 5514: 'address',\n",
              " 40944: 'menjou',\n",
              " 42592: \"'freak'\",\n",
              " 19508: 'dwindling',\n",
              " 9458: 'benson',\n",
              " 52307: 'white’s',\n",
              " 40945: 'shamelessness',\n",
              " 21925: 'impacted',\n",
              " 52308: 'upatz',\n",
              " 3840: 'cusack',\n",
              " 37567: \"flavia's\",\n",
              " 52309: 'effette',\n",
              " 34753: 'influx',\n",
              " 52310: 'boooooooo',\n",
              " 52311: 'dimitrova',\n",
              " 13423: 'houseman',\n",
              " 25259: 'bigas',\n",
              " 52312: 'boylen',\n",
              " 52313: 'phillipenes',\n",
              " 40946: 'fakery',\n",
              " 27658: \"grandpa's\",\n",
              " 27659: 'darnell',\n",
              " 19509: 'undergone',\n",
              " 52315: 'handbags',\n",
              " 21926: 'perished',\n",
              " 37778: 'pooped',\n",
              " 27660: 'vigour',\n",
              " 3627: 'opposed',\n",
              " 52316: 'etude',\n",
              " 11799: \"caine's\",\n",
              " 52317: 'doozers',\n",
              " 34754: 'photojournals',\n",
              " 52318: 'perishes',\n",
              " 34755: 'constrains',\n",
              " 40948: 'migenes',\n",
              " 30605: 'consoled',\n",
              " 16827: 'alastair',\n",
              " 52319: 'wvs',\n",
              " 52320: 'ooooooh',\n",
              " 34756: 'approving',\n",
              " 40949: 'consoles',\n",
              " 52064: 'disparagement',\n",
              " 52322: 'futureistic',\n",
              " 52323: 'rebounding',\n",
              " 52324: \"'date\",\n",
              " 52325: 'gregoire',\n",
              " 21927: 'rutherford',\n",
              " 34757: 'americanised',\n",
              " 82196: 'novikov',\n",
              " 1042: 'following',\n",
              " 34758: 'munroe',\n",
              " 52326: \"morita'\",\n",
              " 52327: 'christenssen',\n",
              " 23106: 'oatmeal',\n",
              " 25260: 'fossey',\n",
              " 40950: 'livered',\n",
              " 13000: 'listens',\n",
              " 76164: \"'marci\",\n",
              " 52330: \"otis's\",\n",
              " 23387: 'thanking',\n",
              " 16019: 'maude',\n",
              " 34759: 'extensions',\n",
              " 52332: 'ameteurish',\n",
              " 52333: \"commender's\",\n",
              " 27661: 'agricultural',\n",
              " 4518: 'convincingly',\n",
              " 17639: 'fueled',\n",
              " 54014: 'mahattan',\n",
              " 40952: \"paris's\",\n",
              " 52336: 'vulkan',\n",
              " 52337: 'stapes',\n",
              " 52338: 'odysessy',\n",
              " 12259: 'harmon',\n",
              " 4252: 'surfing',\n",
              " 23494: 'halloran',\n",
              " 49580: 'unbelieveably',\n",
              " 52339: \"'offed'\",\n",
              " 30607: 'quadrant',\n",
              " 19510: 'inhabiting',\n",
              " 34760: 'nebbish',\n",
              " 40953: 'forebears',\n",
              " 34761: 'skirmish',\n",
              " 52340: 'ocassionally',\n",
              " 52341: \"'resist\",\n",
              " 21928: 'impactful',\n",
              " 52342: 'spicier',\n",
              " 40954: 'touristy',\n",
              " 52343: \"'football'\",\n",
              " 40955: 'webpage',\n",
              " 52345: 'exurbia',\n",
              " 52346: 'jucier',\n",
              " 14901: 'professors',\n",
              " 34762: 'structuring',\n",
              " 30608: 'jig',\n",
              " 40956: 'overlord',\n",
              " 25261: 'disconnect',\n",
              " 82201: 'sniffle',\n",
              " 40957: 'slimeball',\n",
              " 40958: 'jia',\n",
              " 16828: 'milked',\n",
              " 40959: 'banjoes',\n",
              " 1237: 'jim',\n",
              " 52348: 'workforces',\n",
              " 52349: 'jip',\n",
              " 52350: 'rotweiller',\n",
              " 34763: 'mundaneness',\n",
              " 52351: \"'ninja'\",\n",
              " 11040: \"dead'\",\n",
              " 40960: \"cipriani's\",\n",
              " 20608: 'modestly',\n",
              " 52352: \"professor'\",\n",
              " 40961: 'shacked',\n",
              " 34764: 'bashful',\n",
              " 23388: 'sorter',\n",
              " 16120: 'overpowering',\n",
              " 18521: 'workmanlike',\n",
              " 27662: 'henpecked',\n",
              " 18522: 'sorted',\n",
              " 52354: \"jōb's\",\n",
              " 52355: \"'always\",\n",
              " 34765: \"'baptists\",\n",
              " 52356: 'dreamcatchers',\n",
              " 52357: \"'silence'\",\n",
              " 21929: 'hickory',\n",
              " 52358: 'fun\\x97yet',\n",
              " 52359: 'breakumentary',\n",
              " 15496: 'didn',\n",
              " 52360: 'didi',\n",
              " 52361: 'pealing',\n",
              " 40962: 'dispite',\n",
              " 25262: \"italy's\",\n",
              " 21930: 'instability',\n",
              " 6539: 'quarter',\n",
              " 12608: 'quartet',\n",
              " 52362: 'padmé',\n",
              " 52363: \"'bleedmedry\",\n",
              " 52364: 'pahalniuk',\n",
              " 52365: 'honduras',\n",
              " 10786: 'bursting',\n",
              " 41465: \"pablo's\",\n",
              " 52367: 'irremediably',\n",
              " 40963: 'presages',\n",
              " 57832: 'bowlegged',\n",
              " 65183: 'dalip',\n",
              " 6260: 'entering',\n",
              " 76172: 'newsradio',\n",
              " 54150: 'presaged',\n",
              " 27663: \"giallo's\",\n",
              " 40964: 'bouyant',\n",
              " 52368: 'amerterish',\n",
              " 18523: 'rajni',\n",
              " 30610: 'leeves',\n",
              " 34767: 'macauley',\n",
              " 612: 'seriously',\n",
              " 52369: 'sugercoma',\n",
              " 52370: 'grimstead',\n",
              " 52371: \"'fairy'\",\n",
              " 30611: 'zenda',\n",
              " 52372: \"'twins'\",\n",
              " 17640: 'realisation',\n",
              " 27664: 'highsmith',\n",
              " 7817: 'raunchy',\n",
              " 40965: 'incentives',\n",
              " 52374: 'flatson',\n",
              " 35097: 'snooker',\n",
              " 16829: 'crazies',\n",
              " 14902: 'crazier',\n",
              " 7094: 'grandma',\n",
              " 52375: 'napunsaktha',\n",
              " 30612: 'workmanship',\n",
              " 52376: 'reisner',\n",
              " 61306: \"sanford's\",\n",
              " 52377: '\\x91doña',\n",
              " 6108: 'modest',\n",
              " 19153: \"everything's\",\n",
              " 40966: 'hamer',\n",
              " 52379: \"couldn't'\",\n",
              " 13001: 'quibble',\n",
              " 52380: 'socking',\n",
              " 21931: 'tingler',\n",
              " 52381: 'gutman',\n",
              " 40967: 'lachlan',\n",
              " 52382: 'tableaus',\n",
              " 52383: 'headbanger',\n",
              " 2847: 'spoken',\n",
              " 34768: 'cerebrally',\n",
              " 23490: \"'road\",\n",
              " 21932: 'tableaux',\n",
              " 40968: \"proust's\",\n",
              " 40969: 'periodical',\n",
              " 52385: \"shoveller's\",\n",
              " 25263: 'tamara',\n",
              " 17641: 'affords',\n",
              " 3249: 'concert',\n",
              " 87955: \"yara's\",\n",
              " 52386: 'someome',\n",
              " 8424: 'lingering',\n",
              " 41511: \"abraham's\",\n",
              " 34769: 'beesley',\n",
              " 34770: 'cherbourg',\n",
              " 28624: 'kagan',\n",
              " 9097: 'snatch',\n",
              " 9260: \"miyazaki's\",\n",
              " 25264: 'absorbs',\n",
              " 40970: \"koltai's\",\n",
              " 64027: 'tingled',\n",
              " 19511: 'crossroads',\n",
              " 16121: 'rehab',\n",
              " 52389: 'falworth',\n",
              " 52390: 'sequals',\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fCPC_WN-eCyw",
        "colab": {}
      },
      "source": [
        "#Define maximum number of words to consider in each review\n",
        "max_review_length = 300\n",
        "\n",
        "#Pad training and test reviews\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
        "                                                        maxlen=max_review_length\n",
        "                                                        )\n",
        "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, \n",
        "                                                       maxlen=max_review_length \n",
        "                                                       )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dybtUgUReCy8"
      },
      "source": [
        "## Build Keras Embedding Layer Model\n",
        "We can think of the Embedding layer as a dicionary that maps a index assigned to a word to a word vector. This layer is very flexible and can be used in a few ways:\n",
        "\n",
        "* The embedding layer can be used at the start of a larger deep learning model. \n",
        "* Also we could load pre-train word embeddings into the embedding layer when we create our model.\n",
        "* Use the embedding layer to train our own word2vec models.\n",
        "\n",
        "The keras embedding layer doesn't require us to onehot encode our words, instead we have to give each word a unqiue intger number as an id. For the imdb dataset we've loaded this has already been done, but if this wasn't the case we could use sklearn [LabelEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A5OLM4eBeCy9",
        "outputId": "6dbb0cb1-175d-4f90-a46d-8abaf7b09268",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 987
        }
      },
      "source": [
        "# Model\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import LSTM\n",
        "\n",
        "# create the model\n",
        "model = Sequential()\n",
        "\n",
        "#Embdedding layer\n",
        "\n",
        "model.add(Embedding(vocab_size, 50, input_length=max_review_length))\n",
        "\n",
        "#LSTM Layer\n",
        "model.add(LSTM(256, dropout=0.2, recurrent_dropout=0.2)) \n",
        "\n",
        "#Dense layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile layer\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Model Summary\n",
        "model.summary()\n",
        "\n",
        "# Fit the model\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=2, batch_size=128, verbose=2)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 300, 50)           500000    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 256)               314368    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 814,625\n",
            "Trainable params: 814,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/2\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            " - 158s - loss: 0.5392 - acc: 0.7267 - val_loss: 0.5240 - val_acc: 0.7354\n",
            "Epoch 2/2\n",
            " - 156s - loss: 0.3663 - acc: 0.8476 - val_loss: 0.3553 - val_acc: 0.8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa0794cbe80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEU09R_BF6aD",
        "colab_type": "code",
        "outputId": "97cf63ba-c872-4bb7-d300-758a181ddbf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Accuracy of the model built\n",
        "\n",
        "accuracy= model.evaluate(x_test, y_test)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy[1]*100))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 162s 6ms/step\n",
            "Accuracy: 84.70%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Igq8Qm8GeCzG"
      },
      "source": [
        "## Retrive the output of each layer in keras for a given single test sample from the trained model you built"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQdMIeAxYyZ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c470d9d6-256b-41b0-e972-b507b2372de2"
      },
      "source": [
        "# Output of Embedded layer\n",
        "\n",
        "# create the model\n",
        "model = Sequential()\n",
        "\n",
        "#Embdedding layer\n",
        "\n",
        "model.add(Embedding(vocab_size, 50, input_length=max_review_length))\n",
        "model.output"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'embedding_2/embedding_lookup/Identity:0' shape=(?, 300, 50) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiQHu1TOYx_6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6c22964e-1c0d-47d4-d918-a1a4a12845f1"
      },
      "source": [
        "# Output of LSTM Layer\n",
        "\n",
        "#LSTM Layer\n",
        "model.add(LSTM(256, dropout=0.2, recurrent_dropout=0.2)) \n",
        "model.output\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'lstm_2/TensorArrayReadV3:0' shape=(?, 256) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIHvRIL_ZYuQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "581e0122-cc6e-4cdd-8319-0b8cb188e234"
      },
      "source": [
        "# Dense layer\n",
        "\n",
        "#Dense layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.output"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'dense_2/Sigmoid:0' shape=(?, 1) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znLLDcLxZfuo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "9511c600-2973-495d-ef7c-4a2c5a5d6b16"
      },
      "source": [
        "# Compile layer\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# Model Summary\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 300, 50)           500000    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 256)               314368    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 814,625\n",
            "Trainable params: 814,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDklAhyxYy_L",
        "colab_type": "text"
      },
      "source": [
        "**Predicting the output for a few samples**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0AqOnLa2eCzH",
        "colab": {}
      },
      "source": [
        "# Predicting the Test set\n",
        "\n",
        "y_pred=model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-dUDSg7VeCzM",
        "outputId": "1e7bb3eb-ae3b-4fb3-e197-649d96338517",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "source": [
        "# Print some reviews with actual and predicted output for test set\n",
        "\n",
        "import pandas as pd\n",
        "text=[]\n",
        "actual=[]\n",
        "predicted=[]\n",
        "for i in range(0,5):\n",
        "  text.append(' '.join(id_to_word[id] for id in x_test[i] ))\n",
        "  actual.append(y_test[i])\n",
        "  predicted.append(y_pred[i])\n",
        " \n",
        "sample_test = pd.DataFrame( {'Review': text, 'Actual Sentiment': actual,  'Predicted Sentiment': predicted  })\n",
        "sample_test"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Actual Sentiment</th>\n",
              "      <th>Predicted Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the please give this one a miss br br and and ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.26843128]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the this film and a lot of and because it and ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.95369613]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the many animation and and and and the great a...</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.6197295]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the i and love this type of movie however this...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.2754928]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>the like some other people and i'm a die hard ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.9803919]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review  ...  Predicted Sentiment\n",
              "0  the please give this one a miss br br and and ...  ...         [0.26843128]\n",
              "1  the this film and a lot of and because it and ...  ...         [0.95369613]\n",
              "2  the many animation and and and and the great a...  ...          [0.6197295]\n",
              "3  the i and love this type of movie however this...  ...          [0.2754928]\n",
              "4  the like some other people and i'm a die hard ...  ...          [0.9803919]\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}