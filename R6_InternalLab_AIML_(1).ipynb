{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R6_InternalLab_AIML (1).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "YJRBuqXhOB7_",
        "OiV4iIFSOw7r",
        "D6nG3EZEOw7v",
        "Ml76geO2Ow7z",
        "jNpWgUzZOw73",
        "7aT3oXsHOw7-"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sb7Epo0VOB58"
      },
      "source": [
        "### Load tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fHpCNRv1OB5-",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNyoxN9AOw5n",
        "colab_type": "text"
      },
      "source": [
        "### Enable Eager Execution if you are using tensorflow 1.x"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tnSsH8sNOB6F",
        "colab": {}
      },
      "source": [
        "tf.VERSION\n",
        "\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-nf--zYPmyv",
        "colab_type": "text"
      },
      "source": [
        "tf.enable_eager_execution()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DxJDmJqqOB6K"
      },
      "source": [
        "### Collect Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FhllFLyKOB6N",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B4yQKMiJOB6R",
        "outputId": "3cae248b-6295-48e1-f13b-6ac91eea7b94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data = pd.read_csv('prices.csv')\n",
        "                   \n",
        "data"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>symbol</th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-01-05 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>123.430000</td>\n",
              "      <td>125.839996</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "      <td>2163600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-01-06 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.980003</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "      <td>2386400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-01-07 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.949997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "      <td>2489500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-01-08 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>115.480003</td>\n",
              "      <td>116.620003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "      <td>2006300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-01-11 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.970001</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "      <td>1408600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2016-01-12 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>115.510002</td>\n",
              "      <td>115.550003</td>\n",
              "      <td>114.500000</td>\n",
              "      <td>116.059998</td>\n",
              "      <td>1098000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2016-01-13 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>116.459999</td>\n",
              "      <td>112.849998</td>\n",
              "      <td>112.589996</td>\n",
              "      <td>117.070000</td>\n",
              "      <td>949600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2016-01-14 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>113.510002</td>\n",
              "      <td>114.379997</td>\n",
              "      <td>110.050003</td>\n",
              "      <td>115.029999</td>\n",
              "      <td>785300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2016-01-15 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>113.330002</td>\n",
              "      <td>112.529999</td>\n",
              "      <td>111.919998</td>\n",
              "      <td>114.879997</td>\n",
              "      <td>1093700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2016-01-19 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>113.660004</td>\n",
              "      <td>110.379997</td>\n",
              "      <td>109.870003</td>\n",
              "      <td>115.870003</td>\n",
              "      <td>1523500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2016-01-20 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>109.059998</td>\n",
              "      <td>109.300003</td>\n",
              "      <td>108.320000</td>\n",
              "      <td>111.599998</td>\n",
              "      <td>1653900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2016-01-21 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>109.730003</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>108.320000</td>\n",
              "      <td>110.580002</td>\n",
              "      <td>944300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2016-01-22 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>111.879997</td>\n",
              "      <td>111.949997</td>\n",
              "      <td>110.190002</td>\n",
              "      <td>112.949997</td>\n",
              "      <td>744900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2016-01-25 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>111.320000</td>\n",
              "      <td>110.120003</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>114.629997</td>\n",
              "      <td>703800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2016-01-26 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>110.419998</td>\n",
              "      <td>111.000000</td>\n",
              "      <td>107.300003</td>\n",
              "      <td>111.400002</td>\n",
              "      <td>563100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2016-01-27 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>110.769997</td>\n",
              "      <td>110.709999</td>\n",
              "      <td>109.019997</td>\n",
              "      <td>112.570000</td>\n",
              "      <td>896100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2016-01-28 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>110.900002</td>\n",
              "      <td>112.580002</td>\n",
              "      <td>109.900002</td>\n",
              "      <td>112.970001</td>\n",
              "      <td>680400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2016-01-29 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>113.349998</td>\n",
              "      <td>114.470001</td>\n",
              "      <td>111.669998</td>\n",
              "      <td>114.589996</td>\n",
              "      <td>749900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2016-02-01 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>114.500000</td>\n",
              "      <td>112.900002</td>\n",
              "      <td>114.849998</td>\n",
              "      <td>574200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2016-02-02 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>113.250000</td>\n",
              "      <td>110.559998</td>\n",
              "      <td>109.750000</td>\n",
              "      <td>113.860001</td>\n",
              "      <td>694800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2016-02-03 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>113.379997</td>\n",
              "      <td>114.050003</td>\n",
              "      <td>109.639999</td>\n",
              "      <td>114.639999</td>\n",
              "      <td>896300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2016-02-04 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>114.080002</td>\n",
              "      <td>115.709999</td>\n",
              "      <td>114.080002</td>\n",
              "      <td>116.320000</td>\n",
              "      <td>956300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2016-02-05 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>115.120003</td>\n",
              "      <td>114.019997</td>\n",
              "      <td>109.709999</td>\n",
              "      <td>116.489998</td>\n",
              "      <td>997100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2016-02-08 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>113.300003</td>\n",
              "      <td>111.160004</td>\n",
              "      <td>110.459999</td>\n",
              "      <td>113.300003</td>\n",
              "      <td>1200500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2016-02-09 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>111.169998</td>\n",
              "      <td>110.650002</td>\n",
              "      <td>109.639999</td>\n",
              "      <td>112.110001</td>\n",
              "      <td>1725200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2016-02-10 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>106.730003</td>\n",
              "      <td>107.519997</td>\n",
              "      <td>106.360001</td>\n",
              "      <td>112.110001</td>\n",
              "      <td>1946000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2016-02-11 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>105.629997</td>\n",
              "      <td>107.129997</td>\n",
              "      <td>104.110001</td>\n",
              "      <td>109.260002</td>\n",
              "      <td>1319500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2016-02-12 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>108.559998</td>\n",
              "      <td>107.839996</td>\n",
              "      <td>107.070000</td>\n",
              "      <td>109.430000</td>\n",
              "      <td>922400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2016-02-16 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>109.110001</td>\n",
              "      <td>110.769997</td>\n",
              "      <td>107.010002</td>\n",
              "      <td>111.300003</td>\n",
              "      <td>1185100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2016-02-17 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>110.830002</td>\n",
              "      <td>111.239998</td>\n",
              "      <td>107.970001</td>\n",
              "      <td>112.110001</td>\n",
              "      <td>921500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141614</th>\n",
              "      <td>2011-03-15</td>\n",
              "      <td>GRMN</td>\n",
              "      <td>33.169998</td>\n",
              "      <td>34.349998</td>\n",
              "      <td>33.090000</td>\n",
              "      <td>34.389999</td>\n",
              "      <td>1263400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141615</th>\n",
              "      <td>2011-03-15</td>\n",
              "      <td>GS</td>\n",
              "      <td>156.059998</td>\n",
              "      <td>157.250000</td>\n",
              "      <td>154.850006</td>\n",
              "      <td>158.050003</td>\n",
              "      <td>5243600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141616</th>\n",
              "      <td>2011-03-15</td>\n",
              "      <td>GT</td>\n",
              "      <td>14.280000</td>\n",
              "      <td>14.950000</td>\n",
              "      <td>14.170000</td>\n",
              "      <td>15.100000</td>\n",
              "      <td>7255600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141617</th>\n",
              "      <td>2011-03-15</td>\n",
              "      <td>GWW</td>\n",
              "      <td>132.490005</td>\n",
              "      <td>134.389999</td>\n",
              "      <td>132.029999</td>\n",
              "      <td>135.330002</td>\n",
              "      <td>466500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141618</th>\n",
              "      <td>2011-03-15</td>\n",
              "      <td>HAL</td>\n",
              "      <td>43.360001</td>\n",
              "      <td>44.009998</td>\n",
              "      <td>42.779999</td>\n",
              "      <td>44.500000</td>\n",
              "      <td>14293000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141619</th>\n",
              "      <td>2011-03-15</td>\n",
              "      <td>HAR</td>\n",
              "      <td>46.299999</td>\n",
              "      <td>46.560001</td>\n",
              "      <td>45.540001</td>\n",
              "      <td>46.930000</td>\n",
              "      <td>644400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141620</th>\n",
              "      <td>2011-03-15</td>\n",
              "      <td>HAS</td>\n",
              "      <td>45.980000</td>\n",
              "      <td>46.040001</td>\n",
              "      <td>45.580002</td>\n",
              "      <td>46.360001</td>\n",
              "      <td>1669800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141621</th>\n",
              "      <td>2011-03-15</td>\n",
              "      <td>HBAN</td>\n",
              "      <td>6.510000</td>\n",
              "      <td>6.640000</td>\n",
              "      <td>6.510000</td>\n",
              "      <td>6.700000</td>\n",
              "      <td>15286200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141622</th>\n",
              "      <td>2011-03-15</td>\n",
              "      <td>HBI</td>\n",
              "      <td>24.870001</td>\n",
              "      <td>26.120001</td>\n",
              "      <td>24.480000</td>\n",
              "      <td>26.200001</td>\n",
              "      <td>6303600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141623</th>\n",
              "      <td>2011-03-15</td>\n",
              "      <td>HCN</td>\n",
              "      <td>51.369999</td>\n",
              "      <td>51.750000</td>\n",
              "      <td>51.099998</td>\n",
              "      <td>52.090000</td>\n",
              "      <td>1590800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141624</th>\n",
              "      <td>2011-03-15</td>\n",
              "      <td>HCP</td>\n",
              "      <td>36.759998</td>\n",
              "      <td>37.570003</td>\n",
              "      <td>36.759998</td>\n",
              "      <td>37.880005</td>\n",
              "      <td>3050100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141625</th>\n",
              "      <td>2011-03-15</td>\n",
              "      <td>HD</td>\n",
              "      <td>35.900002</td>\n",
              "      <td>36.290001</td>\n",
              "      <td>35.820000</td>\n",
              "      <td>36.560001</td>\n",
              "      <td>8897300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141626</th>\n",
              "      <td>2011-03-15</td>\n",
              "      <td>HES</td>\n",
              "      <td>76.360001</td>\n",
              "      <td>78.529999</td>\n",
              "      <td>76.209999</td>\n",
              "      <td>79.300003</td>\n",
              "      <td>3127600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141627</th>\n",
              "      <td>2011-03-15</td>\n",
              "      <td>HIG</td>\n",
              "      <td>25.480000</td>\n",
              "      <td>25.600000</td>\n",
              "      <td>24.170000</td>\n",
              "      <td>25.850000</td>\n",
              "      <td>13064300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141628</th>\n",
              "      <td>2011-03-15</td>\n",
              "      <td>HOG</td>\n",
              "      <td>39.340000</td>\n",
              "      <td>40.849998</td>\n",
              "      <td>39.009998</td>\n",
              "      <td>41.080002</td>\n",
              "      <td>2764300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141629</th>\n",
              "      <td>2011-03-15</td>\n",
              "      <td>HOLX</td>\n",
              "      <td>20.730000</td>\n",
              "      <td>21.270000</td>\n",
              "      <td>20.510000</td>\n",
              "      <td>21.410000</td>\n",
              "      <td>2564800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141630</th>\n",
              "      <td>2011-03-15</td>\n",
              "      <td>HON</td>\n",
              "      <td>54.450001</td>\n",
              "      <td>55.540001</td>\n",
              "      <td>54.189999</td>\n",
              "      <td>55.959999</td>\n",
              "      <td>4794300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141631</th>\n",
              "      <td>2011-03-15</td>\n",
              "      <td>HP</td>\n",
              "      <td>59.810001</td>\n",
              "      <td>61.869999</td>\n",
              "      <td>59.139999</td>\n",
              "      <td>62.380001</td>\n",
              "      <td>1670500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141632</th>\n",
              "      <td>2011-03-15</td>\n",
              "      <td>HPQ</td>\n",
              "      <td>40.619999</td>\n",
              "      <td>40.930000</td>\n",
              "      <td>40.339999</td>\n",
              "      <td>41.190000</td>\n",
              "      <td>48816300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141633</th>\n",
              "      <td>2011-03-15</td>\n",
              "      <td>HRB</td>\n",
              "      <td>15.650000</td>\n",
              "      <td>15.910000</td>\n",
              "      <td>15.510000</td>\n",
              "      <td>16.049999</td>\n",
              "      <td>4989100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141634</th>\n",
              "      <td>2011-03-15</td>\n",
              "      <td>HRL</td>\n",
              "      <td>27.250000</td>\n",
              "      <td>27.219999</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.340000</td>\n",
              "      <td>1654800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141635</th>\n",
              "      <td>2011-03-15</td>\n",
              "      <td>HRS</td>\n",
              "      <td>43.599998</td>\n",
              "      <td>44.250000</td>\n",
              "      <td>43.139999</td>\n",
              "      <td>44.439999</td>\n",
              "      <td>740700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141636</th>\n",
              "      <td>2011-03-15</td>\n",
              "      <td>HSIC</td>\n",
              "      <td>65.610001</td>\n",
              "      <td>65.919998</td>\n",
              "      <td>65.349998</td>\n",
              "      <td>66.959999</td>\n",
              "      <td>611700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141637</th>\n",
              "      <td>2011-03-15</td>\n",
              "      <td>HST</td>\n",
              "      <td>16.639999</td>\n",
              "      <td>17.080000</td>\n",
              "      <td>16.639999</td>\n",
              "      <td>17.230000</td>\n",
              "      <td>12464200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141638</th>\n",
              "      <td>2011-03-15</td>\n",
              "      <td>HSY</td>\n",
              "      <td>52.630001</td>\n",
              "      <td>53.540001</td>\n",
              "      <td>52.220001</td>\n",
              "      <td>53.639999</td>\n",
              "      <td>1877500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141639</th>\n",
              "      <td>2011-03-15</td>\n",
              "      <td>HUM</td>\n",
              "      <td>62.400002</td>\n",
              "      <td>64.010002</td>\n",
              "      <td>62.020000</td>\n",
              "      <td>64.300003</td>\n",
              "      <td>1843700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141640</th>\n",
              "      <td>2011-03-15</td>\n",
              "      <td>IBM</td>\n",
              "      <td>157.350006</td>\n",
              "      <td>159.020004</td>\n",
              "      <td>156.880005</td>\n",
              "      <td>159.639999</td>\n",
              "      <td>6475800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141641</th>\n",
              "      <td>2011-03-15</td>\n",
              "      <td>ICE</td>\n",
              "      <td>121.850004</td>\n",
              "      <td>123.330002</td>\n",
              "      <td>121.210003</td>\n",
              "      <td>124.879999</td>\n",
              "      <td>4092500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141642</th>\n",
              "      <td>2011-03-15</td>\n",
              "      <td>IDXX</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>75.379997</td>\n",
              "      <td>74.839996</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>483400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141643</th>\n",
              "      <td>2011-03-15</td>\n",
              "      <td>IFF</td>\n",
              "      <td>56.119999</td>\n",
              "      <td>57.889999</td>\n",
              "      <td>55.799999</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>141644 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       date symbol  ...        high      volume\n",
              "0       2016-01-05 00:00:00   WLTW  ...  126.250000   2163600.0\n",
              "1       2016-01-06 00:00:00   WLTW  ...  125.540001   2386400.0\n",
              "2       2016-01-07 00:00:00   WLTW  ...  119.739998   2489500.0\n",
              "3       2016-01-08 00:00:00   WLTW  ...  117.440002   2006300.0\n",
              "4       2016-01-11 00:00:00   WLTW  ...  117.330002   1408600.0\n",
              "5       2016-01-12 00:00:00   WLTW  ...  116.059998   1098000.0\n",
              "6       2016-01-13 00:00:00   WLTW  ...  117.070000    949600.0\n",
              "7       2016-01-14 00:00:00   WLTW  ...  115.029999    785300.0\n",
              "8       2016-01-15 00:00:00   WLTW  ...  114.879997   1093700.0\n",
              "9       2016-01-19 00:00:00   WLTW  ...  115.870003   1523500.0\n",
              "10      2016-01-20 00:00:00   WLTW  ...  111.599998   1653900.0\n",
              "11      2016-01-21 00:00:00   WLTW  ...  110.580002    944300.0\n",
              "12      2016-01-22 00:00:00   WLTW  ...  112.949997    744900.0\n",
              "13      2016-01-25 00:00:00   WLTW  ...  114.629997    703800.0\n",
              "14      2016-01-26 00:00:00   WLTW  ...  111.400002    563100.0\n",
              "15      2016-01-27 00:00:00   WLTW  ...  112.570000    896100.0\n",
              "16      2016-01-28 00:00:00   WLTW  ...  112.970001    680400.0\n",
              "17      2016-01-29 00:00:00   WLTW  ...  114.589996    749900.0\n",
              "18      2016-02-01 00:00:00   WLTW  ...  114.849998    574200.0\n",
              "19      2016-02-02 00:00:00   WLTW  ...  113.860001    694800.0\n",
              "20      2016-02-03 00:00:00   WLTW  ...  114.639999    896300.0\n",
              "21      2016-02-04 00:00:00   WLTW  ...  116.320000    956300.0\n",
              "22      2016-02-05 00:00:00   WLTW  ...  116.489998    997100.0\n",
              "23      2016-02-08 00:00:00   WLTW  ...  113.300003   1200500.0\n",
              "24      2016-02-09 00:00:00   WLTW  ...  112.110001   1725200.0\n",
              "25      2016-02-10 00:00:00   WLTW  ...  112.110001   1946000.0\n",
              "26      2016-02-11 00:00:00   WLTW  ...  109.260002   1319500.0\n",
              "27      2016-02-12 00:00:00   WLTW  ...  109.430000    922400.0\n",
              "28      2016-02-16 00:00:00   WLTW  ...  111.300003   1185100.0\n",
              "29      2016-02-17 00:00:00   WLTW  ...  112.110001    921500.0\n",
              "...                     ...    ...  ...         ...         ...\n",
              "141614           2011-03-15   GRMN  ...   34.389999   1263400.0\n",
              "141615           2011-03-15     GS  ...  158.050003   5243600.0\n",
              "141616           2011-03-15     GT  ...   15.100000   7255600.0\n",
              "141617           2011-03-15    GWW  ...  135.330002    466500.0\n",
              "141618           2011-03-15    HAL  ...   44.500000  14293000.0\n",
              "141619           2011-03-15    HAR  ...   46.930000    644400.0\n",
              "141620           2011-03-15    HAS  ...   46.360001   1669800.0\n",
              "141621           2011-03-15   HBAN  ...    6.700000  15286200.0\n",
              "141622           2011-03-15    HBI  ...   26.200001   6303600.0\n",
              "141623           2011-03-15    HCN  ...   52.090000   1590800.0\n",
              "141624           2011-03-15    HCP  ...   37.880005   3050100.0\n",
              "141625           2011-03-15     HD  ...   36.560001   8897300.0\n",
              "141626           2011-03-15    HES  ...   79.300003   3127600.0\n",
              "141627           2011-03-15    HIG  ...   25.850000  13064300.0\n",
              "141628           2011-03-15    HOG  ...   41.080002   2764300.0\n",
              "141629           2011-03-15   HOLX  ...   21.410000   2564800.0\n",
              "141630           2011-03-15    HON  ...   55.959999   4794300.0\n",
              "141631           2011-03-15     HP  ...   62.380001   1670500.0\n",
              "141632           2011-03-15    HPQ  ...   41.190000  48816300.0\n",
              "141633           2011-03-15    HRB  ...   16.049999   4989100.0\n",
              "141634           2011-03-15    HRL  ...   27.340000   1654800.0\n",
              "141635           2011-03-15    HRS  ...   44.439999    740700.0\n",
              "141636           2011-03-15   HSIC  ...   66.959999    611700.0\n",
              "141637           2011-03-15    HST  ...   17.230000  12464200.0\n",
              "141638           2011-03-15    HSY  ...   53.639999   1877500.0\n",
              "141639           2011-03-15    HUM  ...   64.300003   1843700.0\n",
              "141640           2011-03-15    IBM  ...  159.639999   6475800.0\n",
              "141641           2011-03-15    ICE  ...  124.879999   4092500.0\n",
              "141642           2011-03-15   IDXX  ...   76.000000    483400.0\n",
              "141643           2011-03-15    IFF  ...   58.000000         NaN\n",
              "\n",
              "[141644 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDy-aZkzRO_k",
        "colab_type": "code",
        "outputId": "76cc1f32-72f8-4091-b7dc-71878acb1947",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape\n",
        "\n",
        "# 141644 rows\n",
        "# 7 columns"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(141644, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fgkX6SEqOB6W"
      },
      "source": [
        "### Check all columns in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7K8pWsNQOB6X",
        "outputId": "7ecde664-c206-45e5-ecd0-a02b418716e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "data.info()\n",
        "\n",
        "# Date and Symbol are Objects\n",
        "# Other fields are floating points"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 141644 entries, 0 to 141643\n",
            "Data columns (total 7 columns):\n",
            "date      141644 non-null object\n",
            "symbol    141644 non-null object\n",
            "open      141644 non-null float64\n",
            "close     141644 non-null float64\n",
            "low       141644 non-null float64\n",
            "high      141644 non-null float64\n",
            "volume    141643 non-null float64\n",
            "dtypes: float64(5), object(2)\n",
            "memory usage: 7.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7dU6X7MpOB6c"
      },
      "source": [
        "### Drop columns `date` and  `symbol`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lh_6spSKOB6e",
        "outputId": "c91adca4-ac65-44f6-b274-63c6f3a57feb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Dropping Date and Symbol\n",
        "\n",
        "data=data.drop(columns=['date','symbol'])\n",
        "data"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123.430000</td>\n",
              "      <td>125.839996</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "      <td>2163600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.980003</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "      <td>2386400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.949997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "      <td>2489500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>115.480003</td>\n",
              "      <td>116.620003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "      <td>2006300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.970001</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "      <td>1408600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>115.510002</td>\n",
              "      <td>115.550003</td>\n",
              "      <td>114.500000</td>\n",
              "      <td>116.059998</td>\n",
              "      <td>1098000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>116.459999</td>\n",
              "      <td>112.849998</td>\n",
              "      <td>112.589996</td>\n",
              "      <td>117.070000</td>\n",
              "      <td>949600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>113.510002</td>\n",
              "      <td>114.379997</td>\n",
              "      <td>110.050003</td>\n",
              "      <td>115.029999</td>\n",
              "      <td>785300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>113.330002</td>\n",
              "      <td>112.529999</td>\n",
              "      <td>111.919998</td>\n",
              "      <td>114.879997</td>\n",
              "      <td>1093700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>113.660004</td>\n",
              "      <td>110.379997</td>\n",
              "      <td>109.870003</td>\n",
              "      <td>115.870003</td>\n",
              "      <td>1523500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>109.059998</td>\n",
              "      <td>109.300003</td>\n",
              "      <td>108.320000</td>\n",
              "      <td>111.599998</td>\n",
              "      <td>1653900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>109.730003</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>108.320000</td>\n",
              "      <td>110.580002</td>\n",
              "      <td>944300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>111.879997</td>\n",
              "      <td>111.949997</td>\n",
              "      <td>110.190002</td>\n",
              "      <td>112.949997</td>\n",
              "      <td>744900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>111.320000</td>\n",
              "      <td>110.120003</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>114.629997</td>\n",
              "      <td>703800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>110.419998</td>\n",
              "      <td>111.000000</td>\n",
              "      <td>107.300003</td>\n",
              "      <td>111.400002</td>\n",
              "      <td>563100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>110.769997</td>\n",
              "      <td>110.709999</td>\n",
              "      <td>109.019997</td>\n",
              "      <td>112.570000</td>\n",
              "      <td>896100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>110.900002</td>\n",
              "      <td>112.580002</td>\n",
              "      <td>109.900002</td>\n",
              "      <td>112.970001</td>\n",
              "      <td>680400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>113.349998</td>\n",
              "      <td>114.470001</td>\n",
              "      <td>111.669998</td>\n",
              "      <td>114.589996</td>\n",
              "      <td>749900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>114.000000</td>\n",
              "      <td>114.500000</td>\n",
              "      <td>112.900002</td>\n",
              "      <td>114.849998</td>\n",
              "      <td>574200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>113.250000</td>\n",
              "      <td>110.559998</td>\n",
              "      <td>109.750000</td>\n",
              "      <td>113.860001</td>\n",
              "      <td>694800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>113.379997</td>\n",
              "      <td>114.050003</td>\n",
              "      <td>109.639999</td>\n",
              "      <td>114.639999</td>\n",
              "      <td>896300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>114.080002</td>\n",
              "      <td>115.709999</td>\n",
              "      <td>114.080002</td>\n",
              "      <td>116.320000</td>\n",
              "      <td>956300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>115.120003</td>\n",
              "      <td>114.019997</td>\n",
              "      <td>109.709999</td>\n",
              "      <td>116.489998</td>\n",
              "      <td>997100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>113.300003</td>\n",
              "      <td>111.160004</td>\n",
              "      <td>110.459999</td>\n",
              "      <td>113.300003</td>\n",
              "      <td>1200500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>111.169998</td>\n",
              "      <td>110.650002</td>\n",
              "      <td>109.639999</td>\n",
              "      <td>112.110001</td>\n",
              "      <td>1725200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>106.730003</td>\n",
              "      <td>107.519997</td>\n",
              "      <td>106.360001</td>\n",
              "      <td>112.110001</td>\n",
              "      <td>1946000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>105.629997</td>\n",
              "      <td>107.129997</td>\n",
              "      <td>104.110001</td>\n",
              "      <td>109.260002</td>\n",
              "      <td>1319500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>108.559998</td>\n",
              "      <td>107.839996</td>\n",
              "      <td>107.070000</td>\n",
              "      <td>109.430000</td>\n",
              "      <td>922400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>109.110001</td>\n",
              "      <td>110.769997</td>\n",
              "      <td>107.010002</td>\n",
              "      <td>111.300003</td>\n",
              "      <td>1185100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>110.830002</td>\n",
              "      <td>111.239998</td>\n",
              "      <td>107.970001</td>\n",
              "      <td>112.110001</td>\n",
              "      <td>921500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141614</th>\n",
              "      <td>33.169998</td>\n",
              "      <td>34.349998</td>\n",
              "      <td>33.090000</td>\n",
              "      <td>34.389999</td>\n",
              "      <td>1263400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141615</th>\n",
              "      <td>156.059998</td>\n",
              "      <td>157.250000</td>\n",
              "      <td>154.850006</td>\n",
              "      <td>158.050003</td>\n",
              "      <td>5243600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141616</th>\n",
              "      <td>14.280000</td>\n",
              "      <td>14.950000</td>\n",
              "      <td>14.170000</td>\n",
              "      <td>15.100000</td>\n",
              "      <td>7255600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141617</th>\n",
              "      <td>132.490005</td>\n",
              "      <td>134.389999</td>\n",
              "      <td>132.029999</td>\n",
              "      <td>135.330002</td>\n",
              "      <td>466500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141618</th>\n",
              "      <td>43.360001</td>\n",
              "      <td>44.009998</td>\n",
              "      <td>42.779999</td>\n",
              "      <td>44.500000</td>\n",
              "      <td>14293000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141619</th>\n",
              "      <td>46.299999</td>\n",
              "      <td>46.560001</td>\n",
              "      <td>45.540001</td>\n",
              "      <td>46.930000</td>\n",
              "      <td>644400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141620</th>\n",
              "      <td>45.980000</td>\n",
              "      <td>46.040001</td>\n",
              "      <td>45.580002</td>\n",
              "      <td>46.360001</td>\n",
              "      <td>1669800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141621</th>\n",
              "      <td>6.510000</td>\n",
              "      <td>6.640000</td>\n",
              "      <td>6.510000</td>\n",
              "      <td>6.700000</td>\n",
              "      <td>15286200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141622</th>\n",
              "      <td>24.870001</td>\n",
              "      <td>26.120001</td>\n",
              "      <td>24.480000</td>\n",
              "      <td>26.200001</td>\n",
              "      <td>6303600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141623</th>\n",
              "      <td>51.369999</td>\n",
              "      <td>51.750000</td>\n",
              "      <td>51.099998</td>\n",
              "      <td>52.090000</td>\n",
              "      <td>1590800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141624</th>\n",
              "      <td>36.759998</td>\n",
              "      <td>37.570003</td>\n",
              "      <td>36.759998</td>\n",
              "      <td>37.880005</td>\n",
              "      <td>3050100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141625</th>\n",
              "      <td>35.900002</td>\n",
              "      <td>36.290001</td>\n",
              "      <td>35.820000</td>\n",
              "      <td>36.560001</td>\n",
              "      <td>8897300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141626</th>\n",
              "      <td>76.360001</td>\n",
              "      <td>78.529999</td>\n",
              "      <td>76.209999</td>\n",
              "      <td>79.300003</td>\n",
              "      <td>3127600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141627</th>\n",
              "      <td>25.480000</td>\n",
              "      <td>25.600000</td>\n",
              "      <td>24.170000</td>\n",
              "      <td>25.850000</td>\n",
              "      <td>13064300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141628</th>\n",
              "      <td>39.340000</td>\n",
              "      <td>40.849998</td>\n",
              "      <td>39.009998</td>\n",
              "      <td>41.080002</td>\n",
              "      <td>2764300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141629</th>\n",
              "      <td>20.730000</td>\n",
              "      <td>21.270000</td>\n",
              "      <td>20.510000</td>\n",
              "      <td>21.410000</td>\n",
              "      <td>2564800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141630</th>\n",
              "      <td>54.450001</td>\n",
              "      <td>55.540001</td>\n",
              "      <td>54.189999</td>\n",
              "      <td>55.959999</td>\n",
              "      <td>4794300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141631</th>\n",
              "      <td>59.810001</td>\n",
              "      <td>61.869999</td>\n",
              "      <td>59.139999</td>\n",
              "      <td>62.380001</td>\n",
              "      <td>1670500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141632</th>\n",
              "      <td>40.619999</td>\n",
              "      <td>40.930000</td>\n",
              "      <td>40.339999</td>\n",
              "      <td>41.190000</td>\n",
              "      <td>48816300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141633</th>\n",
              "      <td>15.650000</td>\n",
              "      <td>15.910000</td>\n",
              "      <td>15.510000</td>\n",
              "      <td>16.049999</td>\n",
              "      <td>4989100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141634</th>\n",
              "      <td>27.250000</td>\n",
              "      <td>27.219999</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.340000</td>\n",
              "      <td>1654800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141635</th>\n",
              "      <td>43.599998</td>\n",
              "      <td>44.250000</td>\n",
              "      <td>43.139999</td>\n",
              "      <td>44.439999</td>\n",
              "      <td>740700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141636</th>\n",
              "      <td>65.610001</td>\n",
              "      <td>65.919998</td>\n",
              "      <td>65.349998</td>\n",
              "      <td>66.959999</td>\n",
              "      <td>611700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141637</th>\n",
              "      <td>16.639999</td>\n",
              "      <td>17.080000</td>\n",
              "      <td>16.639999</td>\n",
              "      <td>17.230000</td>\n",
              "      <td>12464200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141638</th>\n",
              "      <td>52.630001</td>\n",
              "      <td>53.540001</td>\n",
              "      <td>52.220001</td>\n",
              "      <td>53.639999</td>\n",
              "      <td>1877500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141639</th>\n",
              "      <td>62.400002</td>\n",
              "      <td>64.010002</td>\n",
              "      <td>62.020000</td>\n",
              "      <td>64.300003</td>\n",
              "      <td>1843700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141640</th>\n",
              "      <td>157.350006</td>\n",
              "      <td>159.020004</td>\n",
              "      <td>156.880005</td>\n",
              "      <td>159.639999</td>\n",
              "      <td>6475800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141641</th>\n",
              "      <td>121.850004</td>\n",
              "      <td>123.330002</td>\n",
              "      <td>121.210003</td>\n",
              "      <td>124.879999</td>\n",
              "      <td>4092500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141642</th>\n",
              "      <td>75.000000</td>\n",
              "      <td>75.379997</td>\n",
              "      <td>74.839996</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>483400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141643</th>\n",
              "      <td>56.119999</td>\n",
              "      <td>57.889999</td>\n",
              "      <td>55.799999</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>141644 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              open       close         low        high      volume\n",
              "0       123.430000  125.839996  122.309998  126.250000   2163600.0\n",
              "1       125.239998  119.980003  119.940002  125.540001   2386400.0\n",
              "2       116.379997  114.949997  114.930000  119.739998   2489500.0\n",
              "3       115.480003  116.620003  113.500000  117.440002   2006300.0\n",
              "4       117.010002  114.970001  114.089996  117.330002   1408600.0\n",
              "5       115.510002  115.550003  114.500000  116.059998   1098000.0\n",
              "6       116.459999  112.849998  112.589996  117.070000    949600.0\n",
              "7       113.510002  114.379997  110.050003  115.029999    785300.0\n",
              "8       113.330002  112.529999  111.919998  114.879997   1093700.0\n",
              "9       113.660004  110.379997  109.870003  115.870003   1523500.0\n",
              "10      109.059998  109.300003  108.320000  111.599998   1653900.0\n",
              "11      109.730003  110.000000  108.320000  110.580002    944300.0\n",
              "12      111.879997  111.949997  110.190002  112.949997    744900.0\n",
              "13      111.320000  110.120003  110.000000  114.629997    703800.0\n",
              "14      110.419998  111.000000  107.300003  111.400002    563100.0\n",
              "15      110.769997  110.709999  109.019997  112.570000    896100.0\n",
              "16      110.900002  112.580002  109.900002  112.970001    680400.0\n",
              "17      113.349998  114.470001  111.669998  114.589996    749900.0\n",
              "18      114.000000  114.500000  112.900002  114.849998    574200.0\n",
              "19      113.250000  110.559998  109.750000  113.860001    694800.0\n",
              "20      113.379997  114.050003  109.639999  114.639999    896300.0\n",
              "21      114.080002  115.709999  114.080002  116.320000    956300.0\n",
              "22      115.120003  114.019997  109.709999  116.489998    997100.0\n",
              "23      113.300003  111.160004  110.459999  113.300003   1200500.0\n",
              "24      111.169998  110.650002  109.639999  112.110001   1725200.0\n",
              "25      106.730003  107.519997  106.360001  112.110001   1946000.0\n",
              "26      105.629997  107.129997  104.110001  109.260002   1319500.0\n",
              "27      108.559998  107.839996  107.070000  109.430000    922400.0\n",
              "28      109.110001  110.769997  107.010002  111.300003   1185100.0\n",
              "29      110.830002  111.239998  107.970001  112.110001    921500.0\n",
              "...            ...         ...         ...         ...         ...\n",
              "141614   33.169998   34.349998   33.090000   34.389999   1263400.0\n",
              "141615  156.059998  157.250000  154.850006  158.050003   5243600.0\n",
              "141616   14.280000   14.950000   14.170000   15.100000   7255600.0\n",
              "141617  132.490005  134.389999  132.029999  135.330002    466500.0\n",
              "141618   43.360001   44.009998   42.779999   44.500000  14293000.0\n",
              "141619   46.299999   46.560001   45.540001   46.930000    644400.0\n",
              "141620   45.980000   46.040001   45.580002   46.360001   1669800.0\n",
              "141621    6.510000    6.640000    6.510000    6.700000  15286200.0\n",
              "141622   24.870001   26.120001   24.480000   26.200001   6303600.0\n",
              "141623   51.369999   51.750000   51.099998   52.090000   1590800.0\n",
              "141624   36.759998   37.570003   36.759998   37.880005   3050100.0\n",
              "141625   35.900002   36.290001   35.820000   36.560001   8897300.0\n",
              "141626   76.360001   78.529999   76.209999   79.300003   3127600.0\n",
              "141627   25.480000   25.600000   24.170000   25.850000  13064300.0\n",
              "141628   39.340000   40.849998   39.009998   41.080002   2764300.0\n",
              "141629   20.730000   21.270000   20.510000   21.410000   2564800.0\n",
              "141630   54.450001   55.540001   54.189999   55.959999   4794300.0\n",
              "141631   59.810001   61.869999   59.139999   62.380001   1670500.0\n",
              "141632   40.619999   40.930000   40.339999   41.190000  48816300.0\n",
              "141633   15.650000   15.910000   15.510000   16.049999   4989100.0\n",
              "141634   27.250000   27.219999   27.000000   27.340000   1654800.0\n",
              "141635   43.599998   44.250000   43.139999   44.439999    740700.0\n",
              "141636   65.610001   65.919998   65.349998   66.959999    611700.0\n",
              "141637   16.639999   17.080000   16.639999   17.230000  12464200.0\n",
              "141638   52.630001   53.540001   52.220001   53.639999   1877500.0\n",
              "141639   62.400002   64.010002   62.020000   64.300003   1843700.0\n",
              "141640  157.350006  159.020004  156.880005  159.639999   6475800.0\n",
              "141641  121.850004  123.330002  121.210003  124.879999   4092500.0\n",
              "141642   75.000000   75.379997   74.839996   76.000000    483400.0\n",
              "141643   56.119999   57.889999   55.799999   58.000000         NaN\n",
              "\n",
              "[141644 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENjn-fcGRlAZ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xlwbUgTwOB6i",
        "outputId": "e7882ee6-5770-48f5-afa9-a98c63f65e93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123.430000</td>\n",
              "      <td>125.839996</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "      <td>2163600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.980003</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "      <td>2386400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.949997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "      <td>2489500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>115.480003</td>\n",
              "      <td>116.620003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "      <td>2006300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.970001</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "      <td>1408600.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         open       close         low        high     volume\n",
              "0  123.430000  125.839996  122.309998  126.250000  2163600.0\n",
              "1  125.239998  119.980003  119.940002  125.540001  2386400.0\n",
              "2  116.379997  114.949997  114.930000  119.739998  2489500.0\n",
              "3  115.480003  116.620003  113.500000  117.440002  2006300.0\n",
              "4  117.010002  114.970001  114.089996  117.330002  1408600.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3DBv3WWYOB6q"
      },
      "source": [
        "### Consider only first 1000 rows in the dataset for building feature set and target set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z_hG9rGBOB6s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f803c423-92ef-4e44-f78e-23ba792151f9"
      },
      "source": [
        "# First 1000 rows\n",
        "\n",
        "data1=data.head(1000)\n",
        "data1"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123.430000</td>\n",
              "      <td>125.839996</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "      <td>2163600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.980003</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "      <td>2386400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.949997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "      <td>2489500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>115.480003</td>\n",
              "      <td>116.620003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "      <td>2006300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.970001</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "      <td>1408600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>115.510002</td>\n",
              "      <td>115.550003</td>\n",
              "      <td>114.500000</td>\n",
              "      <td>116.059998</td>\n",
              "      <td>1098000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>116.459999</td>\n",
              "      <td>112.849998</td>\n",
              "      <td>112.589996</td>\n",
              "      <td>117.070000</td>\n",
              "      <td>949600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>113.510002</td>\n",
              "      <td>114.379997</td>\n",
              "      <td>110.050003</td>\n",
              "      <td>115.029999</td>\n",
              "      <td>785300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>113.330002</td>\n",
              "      <td>112.529999</td>\n",
              "      <td>111.919998</td>\n",
              "      <td>114.879997</td>\n",
              "      <td>1093700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>113.660004</td>\n",
              "      <td>110.379997</td>\n",
              "      <td>109.870003</td>\n",
              "      <td>115.870003</td>\n",
              "      <td>1523500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>109.059998</td>\n",
              "      <td>109.300003</td>\n",
              "      <td>108.320000</td>\n",
              "      <td>111.599998</td>\n",
              "      <td>1653900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>109.730003</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>108.320000</td>\n",
              "      <td>110.580002</td>\n",
              "      <td>944300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>111.879997</td>\n",
              "      <td>111.949997</td>\n",
              "      <td>110.190002</td>\n",
              "      <td>112.949997</td>\n",
              "      <td>744900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>111.320000</td>\n",
              "      <td>110.120003</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>114.629997</td>\n",
              "      <td>703800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>110.419998</td>\n",
              "      <td>111.000000</td>\n",
              "      <td>107.300003</td>\n",
              "      <td>111.400002</td>\n",
              "      <td>563100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>110.769997</td>\n",
              "      <td>110.709999</td>\n",
              "      <td>109.019997</td>\n",
              "      <td>112.570000</td>\n",
              "      <td>896100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>110.900002</td>\n",
              "      <td>112.580002</td>\n",
              "      <td>109.900002</td>\n",
              "      <td>112.970001</td>\n",
              "      <td>680400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>113.349998</td>\n",
              "      <td>114.470001</td>\n",
              "      <td>111.669998</td>\n",
              "      <td>114.589996</td>\n",
              "      <td>749900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>114.000000</td>\n",
              "      <td>114.500000</td>\n",
              "      <td>112.900002</td>\n",
              "      <td>114.849998</td>\n",
              "      <td>574200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>113.250000</td>\n",
              "      <td>110.559998</td>\n",
              "      <td>109.750000</td>\n",
              "      <td>113.860001</td>\n",
              "      <td>694800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>113.379997</td>\n",
              "      <td>114.050003</td>\n",
              "      <td>109.639999</td>\n",
              "      <td>114.639999</td>\n",
              "      <td>896300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>114.080002</td>\n",
              "      <td>115.709999</td>\n",
              "      <td>114.080002</td>\n",
              "      <td>116.320000</td>\n",
              "      <td>956300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>115.120003</td>\n",
              "      <td>114.019997</td>\n",
              "      <td>109.709999</td>\n",
              "      <td>116.489998</td>\n",
              "      <td>997100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>113.300003</td>\n",
              "      <td>111.160004</td>\n",
              "      <td>110.459999</td>\n",
              "      <td>113.300003</td>\n",
              "      <td>1200500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>111.169998</td>\n",
              "      <td>110.650002</td>\n",
              "      <td>109.639999</td>\n",
              "      <td>112.110001</td>\n",
              "      <td>1725200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>106.730003</td>\n",
              "      <td>107.519997</td>\n",
              "      <td>106.360001</td>\n",
              "      <td>112.110001</td>\n",
              "      <td>1946000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>105.629997</td>\n",
              "      <td>107.129997</td>\n",
              "      <td>104.110001</td>\n",
              "      <td>109.260002</td>\n",
              "      <td>1319500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>108.559998</td>\n",
              "      <td>107.839996</td>\n",
              "      <td>107.070000</td>\n",
              "      <td>109.430000</td>\n",
              "      <td>922400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>109.110001</td>\n",
              "      <td>110.769997</td>\n",
              "      <td>107.010002</td>\n",
              "      <td>111.300003</td>\n",
              "      <td>1185100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>110.830002</td>\n",
              "      <td>111.239998</td>\n",
              "      <td>107.970001</td>\n",
              "      <td>112.110001</td>\n",
              "      <td>921500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>970</th>\n",
              "      <td>19.240000</td>\n",
              "      <td>18.680000</td>\n",
              "      <td>18.530001</td>\n",
              "      <td>19.430000</td>\n",
              "      <td>9097500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>971</th>\n",
              "      <td>20.520000</td>\n",
              "      <td>20.290001</td>\n",
              "      <td>19.709999</td>\n",
              "      <td>20.549999</td>\n",
              "      <td>2242100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>972</th>\n",
              "      <td>12.950000</td>\n",
              "      <td>13.550000</td>\n",
              "      <td>12.720000</td>\n",
              "      <td>13.600000</td>\n",
              "      <td>6205100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>973</th>\n",
              "      <td>76.059998</td>\n",
              "      <td>75.440002</td>\n",
              "      <td>75.349998</td>\n",
              "      <td>76.370003</td>\n",
              "      <td>864600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>974</th>\n",
              "      <td>19.620001</td>\n",
              "      <td>19.830000</td>\n",
              "      <td>19.480000</td>\n",
              "      <td>19.830000</td>\n",
              "      <td>709200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>975</th>\n",
              "      <td>88.000000</td>\n",
              "      <td>87.370003</td>\n",
              "      <td>87.139999</td>\n",
              "      <td>88.239998</td>\n",
              "      <td>1129600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>976</th>\n",
              "      <td>31.010000</td>\n",
              "      <td>30.959999</td>\n",
              "      <td>30.700001</td>\n",
              "      <td>31.120001</td>\n",
              "      <td>3449300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>977</th>\n",
              "      <td>35.900002</td>\n",
              "      <td>35.189999</td>\n",
              "      <td>34.930000</td>\n",
              "      <td>35.910000</td>\n",
              "      <td>7517100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>978</th>\n",
              "      <td>76.620003</td>\n",
              "      <td>77.650002</td>\n",
              "      <td>76.550003</td>\n",
              "      <td>77.790001</td>\n",
              "      <td>2356500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>979</th>\n",
              "      <td>25.799999</td>\n",
              "      <td>26.420000</td>\n",
              "      <td>25.719999</td>\n",
              "      <td>26.610001</td>\n",
              "      <td>4839200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>980</th>\n",
              "      <td>30.370001</td>\n",
              "      <td>31.059999</td>\n",
              "      <td>30.309999</td>\n",
              "      <td>31.110001</td>\n",
              "      <td>3684600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>981</th>\n",
              "      <td>23.120001</td>\n",
              "      <td>22.920000</td>\n",
              "      <td>22.740000</td>\n",
              "      <td>23.129999</td>\n",
              "      <td>14428400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>982</th>\n",
              "      <td>39.790001</td>\n",
              "      <td>39.610001</td>\n",
              "      <td>39.090000</td>\n",
              "      <td>39.799999</td>\n",
              "      <td>1463300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>983</th>\n",
              "      <td>24.669997</td>\n",
              "      <td>25.140004</td>\n",
              "      <td>24.669997</td>\n",
              "      <td>25.160000</td>\n",
              "      <td>749600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>984</th>\n",
              "      <td>11.250000</td>\n",
              "      <td>11.770000</td>\n",
              "      <td>11.200000</td>\n",
              "      <td>11.790000</td>\n",
              "      <td>13355100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>985</th>\n",
              "      <td>1.630000</td>\n",
              "      <td>1.650000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>1.660000</td>\n",
              "      <td>11538300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>986</th>\n",
              "      <td>17.020000</td>\n",
              "      <td>16.860001</td>\n",
              "      <td>16.790001</td>\n",
              "      <td>17.209999</td>\n",
              "      <td>9931300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>987</th>\n",
              "      <td>257.840004</td>\n",
              "      <td>256.079998</td>\n",
              "      <td>253.050003</td>\n",
              "      <td>257.959995</td>\n",
              "      <td>12906000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>988</th>\n",
              "      <td>48.099998</td>\n",
              "      <td>48.150002</td>\n",
              "      <td>47.700001</td>\n",
              "      <td>48.369999</td>\n",
              "      <td>369900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>989</th>\n",
              "      <td>34.529999</td>\n",
              "      <td>34.430000</td>\n",
              "      <td>34.080002</td>\n",
              "      <td>34.750000</td>\n",
              "      <td>2701000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>990</th>\n",
              "      <td>27.570000</td>\n",
              "      <td>27.790001</td>\n",
              "      <td>27.370000</td>\n",
              "      <td>27.919999</td>\n",
              "      <td>2627800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>991</th>\n",
              "      <td>14.200000</td>\n",
              "      <td>14.420000</td>\n",
              "      <td>14.120000</td>\n",
              "      <td>14.430000</td>\n",
              "      <td>3258700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>992</th>\n",
              "      <td>19.900000</td>\n",
              "      <td>19.580000</td>\n",
              "      <td>19.330000</td>\n",
              "      <td>20.059999</td>\n",
              "      <td>5206100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>993</th>\n",
              "      <td>62.660000</td>\n",
              "      <td>62.299999</td>\n",
              "      <td>62.189999</td>\n",
              "      <td>62.750000</td>\n",
              "      <td>7099000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>994</th>\n",
              "      <td>29.219999</td>\n",
              "      <td>28.719999</td>\n",
              "      <td>28.629999</td>\n",
              "      <td>29.309999</td>\n",
              "      <td>7795500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>63.310001</td>\n",
              "      <td>63.590000</td>\n",
              "      <td>63.240002</td>\n",
              "      <td>63.639999</td>\n",
              "      <td>2133200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>27.160000</td>\n",
              "      <td>26.990000</td>\n",
              "      <td>26.680000</td>\n",
              "      <td>27.299999</td>\n",
              "      <td>1982400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>28.320000</td>\n",
              "      <td>28.770000</td>\n",
              "      <td>28.010000</td>\n",
              "      <td>28.809999</td>\n",
              "      <td>37152800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>44.000000</td>\n",
              "      <td>44.799999</td>\n",
              "      <td>43.750000</td>\n",
              "      <td>44.810001</td>\n",
              "      <td>6568600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>36.080002</td>\n",
              "      <td>37.139999</td>\n",
              "      <td>36.009998</td>\n",
              "      <td>37.230000</td>\n",
              "      <td>5604300.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           open       close         low        high      volume\n",
              "0    123.430000  125.839996  122.309998  126.250000   2163600.0\n",
              "1    125.239998  119.980003  119.940002  125.540001   2386400.0\n",
              "2    116.379997  114.949997  114.930000  119.739998   2489500.0\n",
              "3    115.480003  116.620003  113.500000  117.440002   2006300.0\n",
              "4    117.010002  114.970001  114.089996  117.330002   1408600.0\n",
              "5    115.510002  115.550003  114.500000  116.059998   1098000.0\n",
              "6    116.459999  112.849998  112.589996  117.070000    949600.0\n",
              "7    113.510002  114.379997  110.050003  115.029999    785300.0\n",
              "8    113.330002  112.529999  111.919998  114.879997   1093700.0\n",
              "9    113.660004  110.379997  109.870003  115.870003   1523500.0\n",
              "10   109.059998  109.300003  108.320000  111.599998   1653900.0\n",
              "11   109.730003  110.000000  108.320000  110.580002    944300.0\n",
              "12   111.879997  111.949997  110.190002  112.949997    744900.0\n",
              "13   111.320000  110.120003  110.000000  114.629997    703800.0\n",
              "14   110.419998  111.000000  107.300003  111.400002    563100.0\n",
              "15   110.769997  110.709999  109.019997  112.570000    896100.0\n",
              "16   110.900002  112.580002  109.900002  112.970001    680400.0\n",
              "17   113.349998  114.470001  111.669998  114.589996    749900.0\n",
              "18   114.000000  114.500000  112.900002  114.849998    574200.0\n",
              "19   113.250000  110.559998  109.750000  113.860001    694800.0\n",
              "20   113.379997  114.050003  109.639999  114.639999    896300.0\n",
              "21   114.080002  115.709999  114.080002  116.320000    956300.0\n",
              "22   115.120003  114.019997  109.709999  116.489998    997100.0\n",
              "23   113.300003  111.160004  110.459999  113.300003   1200500.0\n",
              "24   111.169998  110.650002  109.639999  112.110001   1725200.0\n",
              "25   106.730003  107.519997  106.360001  112.110001   1946000.0\n",
              "26   105.629997  107.129997  104.110001  109.260002   1319500.0\n",
              "27   108.559998  107.839996  107.070000  109.430000    922400.0\n",
              "28   109.110001  110.769997  107.010002  111.300003   1185100.0\n",
              "29   110.830002  111.239998  107.970001  112.110001    921500.0\n",
              "..          ...         ...         ...         ...         ...\n",
              "970   19.240000   18.680000   18.530001   19.430000   9097500.0\n",
              "971   20.520000   20.290001   19.709999   20.549999   2242100.0\n",
              "972   12.950000   13.550000   12.720000   13.600000   6205100.0\n",
              "973   76.059998   75.440002   75.349998   76.370003    864600.0\n",
              "974   19.620001   19.830000   19.480000   19.830000    709200.0\n",
              "975   88.000000   87.370003   87.139999   88.239998   1129600.0\n",
              "976   31.010000   30.959999   30.700001   31.120001   3449300.0\n",
              "977   35.900002   35.189999   34.930000   35.910000   7517100.0\n",
              "978   76.620003   77.650002   76.550003   77.790001   2356500.0\n",
              "979   25.799999   26.420000   25.719999   26.610001   4839200.0\n",
              "980   30.370001   31.059999   30.309999   31.110001   3684600.0\n",
              "981   23.120001   22.920000   22.740000   23.129999  14428400.0\n",
              "982   39.790001   39.610001   39.090000   39.799999   1463300.0\n",
              "983   24.669997   25.140004   24.669997   25.160000    749600.0\n",
              "984   11.250000   11.770000   11.200000   11.790000  13355100.0\n",
              "985    1.630000    1.650000    1.600000    1.660000  11538300.0\n",
              "986   17.020000   16.860001   16.790001   17.209999   9931300.0\n",
              "987  257.840004  256.079998  253.050003  257.959995  12906000.0\n",
              "988   48.099998   48.150002   47.700001   48.369999    369900.0\n",
              "989   34.529999   34.430000   34.080002   34.750000   2701000.0\n",
              "990   27.570000   27.790001   27.370000   27.919999   2627800.0\n",
              "991   14.200000   14.420000   14.120000   14.430000   3258700.0\n",
              "992   19.900000   19.580000   19.330000   20.059999   5206100.0\n",
              "993   62.660000   62.299999   62.189999   62.750000   7099000.0\n",
              "994   29.219999   28.719999   28.629999   29.309999   7795500.0\n",
              "995   63.310001   63.590000   63.240002   63.639999   2133200.0\n",
              "996   27.160000   26.990000   26.680000   27.299999   1982400.0\n",
              "997   28.320000   28.770000   28.010000   28.809999  37152800.0\n",
              "998   44.000000   44.799999   43.750000   44.810001   6568600.0\n",
              "999   36.080002   37.139999   36.009998   37.230000   5604300.0\n",
              "\n",
              "[1000 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaILCnKAOw6d",
        "colab_type": "text"
      },
      "source": [
        "### Convert Float64 to Float32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUQSWtgEOw6f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "febc7ccb-0e28-409e-9f24-b545e53a5781"
      },
      "source": [
        "# Converting columns from Float64 to Float32\n",
        "\n",
        "data1['open']=data1['open'].astype('float32')\n",
        "data1['close']=data1['close'].astype('float32')\n",
        "data1['low']=data1['low'].astype('float32')\n",
        "data1['high']=data1['high'].astype('float32')\n",
        "data1['volume']=data1['volume'].astype('float32')"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5OjPPKvZKFM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "4567d646-1f4c-489f-968f-48e89ded8a35"
      },
      "source": [
        "data1.info()\n",
        "\n",
        "# All the columns belonging to Float64 are converted to Float32"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 5 columns):\n",
            "open      1000 non-null float32\n",
            "close     1000 non-null float32\n",
            "low       1000 non-null float32\n",
            "high      1000 non-null float32\n",
            "volume    1000 non-null float32\n",
            "dtypes: float32(5)\n",
            "memory usage: 19.6 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M3UaApqYOB6x"
      },
      "source": [
        "### Divide the data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2EkKAy7fOB6y",
        "colab": {}
      },
      "source": [
        "# Split Train and Test data\n",
        "\n",
        "X= data1.drop(columns='close')\n",
        "y=data1['close']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO8-kqciOw6u",
        "colab_type": "text"
      },
      "source": [
        "### Normalize Train and Test Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIwXur3bOw6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalizae Train and Test data\n",
        "from sklearn.preprocessing import Normalizer\n",
        "transformer = Normalizer()\n",
        "X_train = transformer.fit_transform(X_train)\n",
        "X_test = transformer.fit_transform(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14WsuS3phQa5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1163125f-24d9-418d-cf60-08dbfeb3f5ad"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "498     20.480000\n",
              "243    123.839996\n",
              "314     52.490002\n",
              "202    126.790001\n",
              "300    158.029999\n",
              "682     73.379997\n",
              "230    121.419998\n",
              "306     40.189999\n",
              "166    124.010002\n",
              "620     23.049999\n",
              "724     42.330002\n",
              "263     25.670000\n",
              "326     14.250000\n",
              "232    121.480003\n",
              "150    121.230003\n",
              "469     45.680000\n",
              "132    126.040001\n",
              "9      110.379997\n",
              "254    214.009995\n",
              "952     33.150002\n",
              "379     83.370003\n",
              "581     33.630001\n",
              "82     126.269997\n",
              "64     113.540001\n",
              "767    156.710007\n",
              "369     14.610000\n",
              "528     27.270000\n",
              "449     35.869999\n",
              "119    117.010002\n",
              "773     41.209999\n",
              "          ...    \n",
              "208    125.900002\n",
              "608     24.629999\n",
              "420     49.430000\n",
              "253     40.380001\n",
              "846     47.560001\n",
              "339     30.500000\n",
              "409     48.880001\n",
              "111    124.959999\n",
              "224    124.820000\n",
              "942     30.350000\n",
              "544     30.950001\n",
              "73     122.309998\n",
              "47     120.629997\n",
              "638     20.440001\n",
              "113    124.839996\n",
              "96     125.949997\n",
              "737     29.330000\n",
              "214    118.790001\n",
              "569     45.579998\n",
              "123    124.309998\n",
              "106    129.250000\n",
              "595     60.599998\n",
              "17     114.470001\n",
              "742     36.779999\n",
              "98     126.459999\n",
              "988     48.150002\n",
              "322     32.529999\n",
              "382     29.100000\n",
              "365     38.959999\n",
              "510     76.849998\n",
              "Name: close, Length: 700, dtype: float32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v6vE4eYCOB62"
      },
      "source": [
        "\n",
        "## Building the graph in tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "297_qja4OB7A"
      },
      "source": [
        "2.Define Weights and Bias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L205qPeQOB7B",
        "colab": {}
      },
      "source": [
        "#We are initializing weights and Bias with Zero\n",
        "w = tf.zeros(shape=(4,1))\n",
        "b = tf.zeros(shape=(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HgtWA-UIOB7F"
      },
      "source": [
        "3.Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JveGlx25OB7H",
        "colab": {}
      },
      "source": [
        "# Define a Prediction function to compute prediction values\n",
        "\n",
        "def prediction(x, w, b):\n",
        "    \n",
        "    xw_matmul = tf.matmul(x, w)\n",
        "    y = tf.add(xw_matmul, b)\n",
        "    return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TL1hIwf_OB7M"
      },
      "source": [
        "4.Loss (Cost) Function [Mean square error]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8VSWPiGXOB7P",
        "colab": {}
      },
      "source": [
        "# Define a function to Compiute Loss\n",
        "\n",
        "def loss(y_actual, y_predicted):\n",
        "    \n",
        "    diff = y_actual - y_predicted\n",
        "    sqr = tf.square(diff)\n",
        "    avg = tf.reduce_mean(sqr)\n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jzG85FUlOB7U"
      },
      "source": [
        "5.GradientDescent Optimizer to minimize Loss [GradientDescentOptimizer]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cj802w-3OB7X",
        "colab": {}
      },
      "source": [
        "# Define a GradientDescent function to minimize loss\n",
        "\n",
        "def train(x, y_actual, w, b, learning_rate=0.01):\n",
        "    \n",
        "    #Record mathematical operations on 'tape' to calculate loss\n",
        "    with tf.GradientTape() as t:        \n",
        "        t.watch([w,b])\n",
        "        current_prediction = prediction(x, w, b)\n",
        "        current_loss = loss(y_actual, current_prediction)\n",
        "    \n",
        "    #Calculate Gradients for Loss with respect to Weights and Bias\n",
        "    dw, db = t.gradient(current_loss,[w, b])\n",
        "    \n",
        "    #Update Weights and Bias\n",
        "    w = w - learning_rate*dw\n",
        "    b = b - learning_rate*db\n",
        "    return w, b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xSypb_u8OB7e"
      },
      "source": [
        "## Execute the Graph for 100 epochs and observe the loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DVvgj7eQOB7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0f7dbc16-7a24-41e6-8fc1-d22ad1d174b6"
      },
      "source": [
        "# Execute the Graph/Model for 100 epochs to observe loss\n",
        "import numpy as np\n",
        "\n",
        "for i in range(100):\n",
        "    y_train=np.array(y_train)\n",
        "    w, b = train(X_train, y_train, w, b, learning_rate=0.01)\n",
        "    print('Current Loss on iteration', i, loss(y_train, prediction(X_train, w, b)).numpy())"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current Loss on iteration 0 8343.2705\n",
            "Current Loss on iteration 1 8001.953\n",
            "Current Loss on iteration 2 7687.3936\n",
            "Current Loss on iteration 3 7397.495\n",
            "Current Loss on iteration 4 7130.319\n",
            "Current Loss on iteration 5 6884.0967\n",
            "Current Loss on iteration 6 6657.1743\n",
            "Current Loss on iteration 7 6448.0425\n",
            "Current Loss on iteration 8 6255.311\n",
            "Current Loss on iteration 9 6077.683\n",
            "Current Loss on iteration 10 5913.987\n",
            "Current Loss on iteration 11 5763.12\n",
            "Current Loss on iteration 12 5624.086\n",
            "Current Loss on iteration 13 5495.95\n",
            "Current Loss on iteration 14 5377.858\n",
            "Current Loss on iteration 15 5269.025\n",
            "Current Loss on iteration 16 5168.7266\n",
            "Current Loss on iteration 17 5076.29\n",
            "Current Loss on iteration 18 4991.1016\n",
            "Current Loss on iteration 19 4912.5913\n",
            "Current Loss on iteration 20 4840.238\n",
            "Current Loss on iteration 21 4773.5547\n",
            "Current Loss on iteration 22 4712.099\n",
            "Current Loss on iteration 23 4655.462\n",
            "Current Loss on iteration 24 4603.2646\n",
            "Current Loss on iteration 25 4555.1616\n",
            "Current Loss on iteration 26 4510.8296\n",
            "Current Loss on iteration 27 4469.9727\n",
            "Current Loss on iteration 28 4432.317\n",
            "Current Loss on iteration 29 4397.616\n",
            "Current Loss on iteration 30 4365.6353\n",
            "Current Loss on iteration 31 4336.1636\n",
            "Current Loss on iteration 32 4308.997\n",
            "Current Loss on iteration 33 4283.9614\n",
            "Current Loss on iteration 34 4260.895\n",
            "Current Loss on iteration 35 4239.6313\n",
            "Current Loss on iteration 36 4220.036\n",
            "Current Loss on iteration 37 4201.979\n",
            "Current Loss on iteration 38 4185.335\n",
            "Current Loss on iteration 39 4169.996\n",
            "Current Loss on iteration 40 4155.861\n",
            "Current Loss on iteration 41 4142.8354\n",
            "Current Loss on iteration 42 4130.8267\n",
            "Current Loss on iteration 43 4119.762\n",
            "Current Loss on iteration 44 4109.5645\n",
            "Current Loss on iteration 45 4100.1646\n",
            "Current Loss on iteration 46 4091.505\n",
            "Current Loss on iteration 47 4083.5234\n",
            "Current Loss on iteration 48 4076.1667\n",
            "Current Loss on iteration 49 4069.3901\n",
            "Current Loss on iteration 50 4063.1409\n",
            "Current Loss on iteration 51 4057.3801\n",
            "Current Loss on iteration 52 4052.075\n",
            "Current Loss on iteration 53 4047.185\n",
            "Current Loss on iteration 54 4042.6763\n",
            "Current Loss on iteration 55 4038.5244\n",
            "Current Loss on iteration 56 4034.6958\n",
            "Current Loss on iteration 57 4031.1687\n",
            "Current Loss on iteration 58 4027.917\n",
            "Current Loss on iteration 59 4024.9177\n",
            "Current Loss on iteration 60 4022.158\n",
            "Current Loss on iteration 61 4019.6128\n",
            "Current Loss on iteration 62 4017.2664\n",
            "Current Loss on iteration 63 4015.104\n",
            "Current Loss on iteration 64 4013.1145\n",
            "Current Loss on iteration 65 4011.2776\n",
            "Current Loss on iteration 66 4009.5842\n",
            "Current Loss on iteration 67 4008.0237\n",
            "Current Loss on iteration 68 4006.5884\n",
            "Current Loss on iteration 69 4005.265\n",
            "Current Loss on iteration 70 4004.0422\n",
            "Current Loss on iteration 71 4002.9185\n",
            "Current Loss on iteration 72 4001.8818\n",
            "Current Loss on iteration 73 4000.9253\n",
            "Current Loss on iteration 74 4000.0444\n",
            "Current Loss on iteration 75 3999.2336\n",
            "Current Loss on iteration 76 3998.4841\n",
            "Current Loss on iteration 77 3997.797\n",
            "Current Loss on iteration 78 3997.1626\n",
            "Current Loss on iteration 79 3996.5742\n",
            "Current Loss on iteration 80 3996.0383\n",
            "Current Loss on iteration 81 3995.5398\n",
            "Current Loss on iteration 82 3995.0808\n",
            "Current Loss on iteration 83 3994.6597\n",
            "Current Loss on iteration 84 3994.2688\n",
            "Current Loss on iteration 85 3993.911\n",
            "Current Loss on iteration 86 3993.58\n",
            "Current Loss on iteration 87 3993.2744\n",
            "Current Loss on iteration 88 3992.9956\n",
            "Current Loss on iteration 89 3992.735\n",
            "Current Loss on iteration 90 3992.4973\n",
            "Current Loss on iteration 91 3992.2783\n",
            "Current Loss on iteration 92 3992.0754\n",
            "Current Loss on iteration 93 3991.887\n",
            "Current Loss on iteration 94 3991.7175\n",
            "Current Loss on iteration 95 3991.5588\n",
            "Current Loss on iteration 96 3991.4136\n",
            "Current Loss on iteration 97 3991.2773\n",
            "Current Loss on iteration 98 3991.1533\n",
            "Current Loss on iteration 99 3991.0383\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9smwOW-1OB7k",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9JuLI6bSOB7n",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DOL2ncA1OB7q"
      },
      "source": [
        "### Get the shapes and values of W and b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZGvtyTeuOB7r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "8c79e811-bca3-49f2-fed1-a5cb4d86d922"
      },
      "source": [
        "#Shapes and Values of Weights and Bias\n",
        "print('Weights:\\n', w.numpy())\n",
        "print('Bias:\\n',b.numpy())"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weights:\n",
            " [[2.5196134e-03]\n",
            " [2.4950290e-03]\n",
            " [2.5409432e-03]\n",
            " [3.3785694e+01]]\n",
            "Bias:\n",
            " [33.785698]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vhDtOv5UOB7x",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YJRBuqXhOB7_"
      },
      "source": [
        "### Linear Classification using Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8GoNTWXAOB8C"
      },
      "source": [
        "### Building the simple Neural Network in Keras with one neuron in the dense hidden layer.\n",
        "#### Use Mean square error as loss function and sgd as optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zpeL5rCTOB8D",
        "colab": {}
      },
      "source": [
        "#Initialize Sequential Graph (model)\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "#Add Dense layer for prediction - Keras declares weights and bias automatically\n",
        "model.add(tf.keras.layers.Dense(1, input_shape=(4,)))\n",
        "\n",
        "#Compile the model - add Loss and Gradient Descent optimizer\n",
        "model.compile(optimizer='sgd', loss='mse')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wt-HYFMEOB8G"
      },
      "source": [
        "### Execute the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "66JGJt7GOB8H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e02cd72e-7885-4409-ca67-bf8a66e98303"
      },
      "source": [
        "# Model execution\n",
        "\n",
        "model.fit(X_train, y_train, epochs=100)\n",
        "\n",
        "# Using Tensorflow and Keras, we observe that the loss has been showing a decreasing trend for the range of 100 epoch as can be sen below\n"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "700/700 [==============================] - 0s 415us/sample - loss: 6298.8420\n",
            "Epoch 2/100\n",
            "700/700 [==============================] - 0s 36us/sample - loss: 4371.8825\n",
            "Epoch 3/100\n",
            "700/700 [==============================] - 0s 31us/sample - loss: 4057.3503\n",
            "Epoch 4/100\n",
            "700/700 [==============================] - 0s 32us/sample - loss: 4005.7521\n",
            "Epoch 5/100\n",
            "700/700 [==============================] - 0s 41us/sample - loss: 3998.3099\n",
            "Epoch 6/100\n",
            "700/700 [==============================] - 0s 35us/sample - loss: 3995.9869\n",
            "Epoch 7/100\n",
            "700/700 [==============================] - 0s 31us/sample - loss: 3993.3467\n",
            "Epoch 8/100\n",
            "700/700 [==============================] - 0s 31us/sample - loss: 3993.0465\n",
            "Epoch 9/100\n",
            "700/700 [==============================] - 0s 28us/sample - loss: 3995.1148\n",
            "Epoch 10/100\n",
            "700/700 [==============================] - 0s 28us/sample - loss: 3995.3569\n",
            "Epoch 11/100\n",
            "700/700 [==============================] - 0s 29us/sample - loss: 3993.4436\n",
            "Epoch 12/100\n",
            "700/700 [==============================] - 0s 29us/sample - loss: 3992.9196\n",
            "Epoch 13/100\n",
            "700/700 [==============================] - 0s 30us/sample - loss: 3992.4073\n",
            "Epoch 14/100\n",
            "700/700 [==============================] - 0s 32us/sample - loss: 3992.1529\n",
            "Epoch 15/100\n",
            "700/700 [==============================] - 0s 33us/sample - loss: 3993.0744\n",
            "Epoch 16/100\n",
            "700/700 [==============================] - 0s 29us/sample - loss: 3993.9471\n",
            "Epoch 17/100\n",
            "700/700 [==============================] - 0s 31us/sample - loss: 3996.0915\n",
            "Epoch 18/100\n",
            "700/700 [==============================] - 0s 32us/sample - loss: 3994.9475\n",
            "Epoch 19/100\n",
            "700/700 [==============================] - 0s 31us/sample - loss: 3994.0904\n",
            "Epoch 20/100\n",
            "700/700 [==============================] - 0s 31us/sample - loss: 3994.2780\n",
            "Epoch 21/100\n",
            "700/700 [==============================] - 0s 30us/sample - loss: 3993.5433\n",
            "Epoch 22/100\n",
            "700/700 [==============================] - 0s 31us/sample - loss: 3994.6366\n",
            "Epoch 23/100\n",
            "700/700 [==============================] - 0s 35us/sample - loss: 3991.1256\n",
            "Epoch 24/100\n",
            "700/700 [==============================] - 0s 32us/sample - loss: 3994.9416\n",
            "Epoch 25/100\n",
            "700/700 [==============================] - 0s 33us/sample - loss: 3995.1139\n",
            "Epoch 26/100\n",
            "700/700 [==============================] - 0s 32us/sample - loss: 3993.9933\n",
            "Epoch 27/100\n",
            "700/700 [==============================] - 0s 33us/sample - loss: 3992.7432\n",
            "Epoch 28/100\n",
            "700/700 [==============================] - 0s 32us/sample - loss: 3990.8036\n",
            "Epoch 29/100\n",
            "700/700 [==============================] - 0s 35us/sample - loss: 3992.7432\n",
            "Epoch 30/100\n",
            "700/700 [==============================] - 0s 37us/sample - loss: 3991.2247\n",
            "Epoch 31/100\n",
            "700/700 [==============================] - 0s 36us/sample - loss: 3994.8205\n",
            "Epoch 32/100\n",
            "700/700 [==============================] - 0s 36us/sample - loss: 3994.0781\n",
            "Epoch 33/100\n",
            "700/700 [==============================] - 0s 29us/sample - loss: 3995.0981\n",
            "Epoch 34/100\n",
            "700/700 [==============================] - 0s 31us/sample - loss: 3994.0132\n",
            "Epoch 35/100\n",
            "700/700 [==============================] - 0s 32us/sample - loss: 3995.2847\n",
            "Epoch 36/100\n",
            "700/700 [==============================] - 0s 32us/sample - loss: 3994.6435\n",
            "Epoch 37/100\n",
            "700/700 [==============================] - 0s 44us/sample - loss: 3996.8564\n",
            "Epoch 38/100\n",
            "700/700 [==============================] - 0s 28us/sample - loss: 3994.9355\n",
            "Epoch 39/100\n",
            "700/700 [==============================] - 0s 35us/sample - loss: 3994.1665\n",
            "Epoch 40/100\n",
            "700/700 [==============================] - 0s 36us/sample - loss: 3995.5362\n",
            "Epoch 41/100\n",
            "700/700 [==============================] - 0s 30us/sample - loss: 3993.5469\n",
            "Epoch 42/100\n",
            "700/700 [==============================] - 0s 43us/sample - loss: 3991.3697\n",
            "Epoch 43/100\n",
            "700/700 [==============================] - 0s 36us/sample - loss: 3996.5369\n",
            "Epoch 44/100\n",
            "700/700 [==============================] - 0s 31us/sample - loss: 3994.7834\n",
            "Epoch 45/100\n",
            "700/700 [==============================] - 0s 31us/sample - loss: 3993.7871\n",
            "Epoch 46/100\n",
            "700/700 [==============================] - 0s 30us/sample - loss: 3993.3459\n",
            "Epoch 47/100\n",
            "700/700 [==============================] - 0s 31us/sample - loss: 3994.3564\n",
            "Epoch 48/100\n",
            "700/700 [==============================] - 0s 33us/sample - loss: 3997.4562\n",
            "Epoch 49/100\n",
            "700/700 [==============================] - 0s 28us/sample - loss: 3995.4230\n",
            "Epoch 50/100\n",
            "700/700 [==============================] - 0s 31us/sample - loss: 3992.7307\n",
            "Epoch 51/100\n",
            "700/700 [==============================] - 0s 32us/sample - loss: 3994.0615\n",
            "Epoch 52/100\n",
            "700/700 [==============================] - 0s 31us/sample - loss: 3994.4676\n",
            "Epoch 53/100\n",
            "700/700 [==============================] - 0s 30us/sample - loss: 3993.2153\n",
            "Epoch 54/100\n",
            "700/700 [==============================] - 0s 33us/sample - loss: 3992.8911\n",
            "Epoch 55/100\n",
            "700/700 [==============================] - 0s 33us/sample - loss: 3993.5511\n",
            "Epoch 56/100\n",
            "700/700 [==============================] - 0s 28us/sample - loss: 3993.2570\n",
            "Epoch 57/100\n",
            "700/700 [==============================] - 0s 30us/sample - loss: 3995.1174\n",
            "Epoch 58/100\n",
            "700/700 [==============================] - 0s 34us/sample - loss: 3993.5635\n",
            "Epoch 59/100\n",
            "700/700 [==============================] - 0s 34us/sample - loss: 3992.0702\n",
            "Epoch 60/100\n",
            "700/700 [==============================] - 0s 40us/sample - loss: 3992.0879\n",
            "Epoch 61/100\n",
            "700/700 [==============================] - 0s 29us/sample - loss: 3995.5619\n",
            "Epoch 62/100\n",
            "700/700 [==============================] - 0s 31us/sample - loss: 3993.1756\n",
            "Epoch 63/100\n",
            "700/700 [==============================] - 0s 33us/sample - loss: 3992.6430\n",
            "Epoch 64/100\n",
            "700/700 [==============================] - 0s 28us/sample - loss: 3993.3153\n",
            "Epoch 65/100\n",
            "700/700 [==============================] - 0s 31us/sample - loss: 3995.1823\n",
            "Epoch 66/100\n",
            "700/700 [==============================] - 0s 30us/sample - loss: 3994.4680\n",
            "Epoch 67/100\n",
            "700/700 [==============================] - 0s 29us/sample - loss: 3993.9607\n",
            "Epoch 68/100\n",
            "700/700 [==============================] - 0s 31us/sample - loss: 3997.0391\n",
            "Epoch 69/100\n",
            "700/700 [==============================] - 0s 31us/sample - loss: 3993.1483\n",
            "Epoch 70/100\n",
            "700/700 [==============================] - 0s 36us/sample - loss: 3993.9379\n",
            "Epoch 71/100\n",
            "700/700 [==============================] - 0s 34us/sample - loss: 3994.5555\n",
            "Epoch 72/100\n",
            "700/700 [==============================] - 0s 35us/sample - loss: 3994.2940\n",
            "Epoch 73/100\n",
            "700/700 [==============================] - 0s 30us/sample - loss: 3991.3557\n",
            "Epoch 74/100\n",
            "700/700 [==============================] - 0s 32us/sample - loss: 3993.1674\n",
            "Epoch 75/100\n",
            "700/700 [==============================] - 0s 30us/sample - loss: 3994.5000\n",
            "Epoch 76/100\n",
            "700/700 [==============================] - 0s 41us/sample - loss: 3993.8388\n",
            "Epoch 77/100\n",
            "700/700 [==============================] - 0s 32us/sample - loss: 3996.2666\n",
            "Epoch 78/100\n",
            "700/700 [==============================] - 0s 34us/sample - loss: 3993.6174\n",
            "Epoch 79/100\n",
            "700/700 [==============================] - 0s 29us/sample - loss: 3994.7594\n",
            "Epoch 80/100\n",
            "700/700 [==============================] - 0s 32us/sample - loss: 3992.2953\n",
            "Epoch 81/100\n",
            "700/700 [==============================] - 0s 32us/sample - loss: 3996.2838\n",
            "Epoch 82/100\n",
            "700/700 [==============================] - 0s 31us/sample - loss: 3995.9158\n",
            "Epoch 83/100\n",
            "700/700 [==============================] - 0s 34us/sample - loss: 3996.4999\n",
            "Epoch 84/100\n",
            "700/700 [==============================] - 0s 36us/sample - loss: 3992.1057\n",
            "Epoch 85/100\n",
            "700/700 [==============================] - 0s 32us/sample - loss: 3992.2661\n",
            "Epoch 86/100\n",
            "700/700 [==============================] - 0s 36us/sample - loss: 3993.5594\n",
            "Epoch 87/100\n",
            "700/700 [==============================] - 0s 43us/sample - loss: 3994.1973\n",
            "Epoch 88/100\n",
            "700/700 [==============================] - 0s 33us/sample - loss: 3995.4226\n",
            "Epoch 89/100\n",
            "700/700 [==============================] - 0s 33us/sample - loss: 3995.5152\n",
            "Epoch 90/100\n",
            "700/700 [==============================] - 0s 31us/sample - loss: 3993.6165\n",
            "Epoch 91/100\n",
            "700/700 [==============================] - 0s 40us/sample - loss: 3995.2661\n",
            "Epoch 92/100\n",
            "700/700 [==============================] - 0s 34us/sample - loss: 3993.5512\n",
            "Epoch 93/100\n",
            "700/700 [==============================] - 0s 31us/sample - loss: 3994.1074\n",
            "Epoch 94/100\n",
            "700/700 [==============================] - 0s 33us/sample - loss: 3997.1061\n",
            "Epoch 95/100\n",
            "700/700 [==============================] - 0s 31us/sample - loss: 3994.6960\n",
            "Epoch 96/100\n",
            "700/700 [==============================] - 0s 31us/sample - loss: 3993.2248\n",
            "Epoch 97/100\n",
            "700/700 [==============================] - 0s 33us/sample - loss: 3994.2934\n",
            "Epoch 98/100\n",
            "700/700 [==============================] - 0s 31us/sample - loss: 3994.0176\n",
            "Epoch 99/100\n",
            "700/700 [==============================] - 0s 38us/sample - loss: 3993.1733\n",
            "Epoch 100/100\n",
            "700/700 [==============================] - 0s 29us/sample - loss: 3993.3518\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5cc77ece80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E17Iesx5Ow7f",
        "colab_type": "text"
      },
      "source": [
        "### Classification using Keras "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6CzJkrFOw7g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "e8cd863c-89e3-4531-b97f-a90d7608ca03"
      },
      "source": [
        "# Result of the model using Keras\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 1)                 5         \n",
            "=================================================================\n",
            "Total params: 5\n",
            "Trainable params: 5\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MQit-7oOw7j",
        "colab_type": "text"
      },
      "source": [
        "### Load the given Iris data using pandas (Iris.csv)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYT-MY3-Ow7k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e7ecbeab-c6b4-4591-e6e7-cf0c3bb24971"
      },
      "source": [
        "# Importing Iris dataset\n",
        "\n",
        "iris = pd.read_csv('Iris-2.csv')\n",
        "                \n",
        "iris"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>5.4</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.4</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>4.4</td>\n",
              "      <td>2.9</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>5.4</td>\n",
              "      <td>3.7</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>4.8</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>4.8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.1</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>4.3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>5.8</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>5.7</td>\n",
              "      <td>4.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>5.4</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.4</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19</td>\n",
              "      <td>5.7</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.3</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.3</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>21</td>\n",
              "      <td>5.4</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>22</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.7</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>23</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>24</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.5</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>25</td>\n",
              "      <td>4.8</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>26</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>27</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.4</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>28</td>\n",
              "      <td>5.2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>29</td>\n",
              "      <td>5.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>30</td>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>121</td>\n",
              "      <td>6.9</td>\n",
              "      <td>3.2</td>\n",
              "      <td>5.7</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>122</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2.8</td>\n",
              "      <td>4.9</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>123</td>\n",
              "      <td>7.7</td>\n",
              "      <td>2.8</td>\n",
              "      <td>6.7</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>124</td>\n",
              "      <td>6.3</td>\n",
              "      <td>2.7</td>\n",
              "      <td>4.9</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>125</td>\n",
              "      <td>6.7</td>\n",
              "      <td>3.3</td>\n",
              "      <td>5.7</td>\n",
              "      <td>2.1</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>126</td>\n",
              "      <td>7.2</td>\n",
              "      <td>3.2</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>127</td>\n",
              "      <td>6.2</td>\n",
              "      <td>2.8</td>\n",
              "      <td>4.8</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>128</td>\n",
              "      <td>6.1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.9</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>129</td>\n",
              "      <td>6.4</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2.1</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>130</td>\n",
              "      <td>7.2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>1.6</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>131</td>\n",
              "      <td>7.4</td>\n",
              "      <td>2.8</td>\n",
              "      <td>6.1</td>\n",
              "      <td>1.9</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>132</td>\n",
              "      <td>7.9</td>\n",
              "      <td>3.8</td>\n",
              "      <td>6.4</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>133</td>\n",
              "      <td>6.4</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2.2</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>134</td>\n",
              "      <td>6.3</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>135</td>\n",
              "      <td>6.1</td>\n",
              "      <td>2.6</td>\n",
              "      <td>5.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>136</td>\n",
              "      <td>7.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.1</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>137</td>\n",
              "      <td>6.3</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2.4</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>138</td>\n",
              "      <td>6.4</td>\n",
              "      <td>3.1</td>\n",
              "      <td>5.5</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>139</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.8</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>140</td>\n",
              "      <td>6.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.1</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>141</td>\n",
              "      <td>6.7</td>\n",
              "      <td>3.1</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2.4</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>142</td>\n",
              "      <td>6.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>5.1</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>143</td>\n",
              "      <td>5.8</td>\n",
              "      <td>2.7</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.9</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>144</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3.2</td>\n",
              "      <td>5.9</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>145</td>\n",
              "      <td>6.7</td>\n",
              "      <td>3.3</td>\n",
              "      <td>5.7</td>\n",
              "      <td>2.5</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>146</td>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>147</td>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>148</td>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>149</td>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>150</td>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Id  SepalLengthCm  ...  PetalWidthCm         Species\n",
              "0      1            5.1  ...           0.2     Iris-setosa\n",
              "1      2            4.9  ...           0.2     Iris-setosa\n",
              "2      3            4.7  ...           0.2     Iris-setosa\n",
              "3      4            4.6  ...           0.2     Iris-setosa\n",
              "4      5            5.0  ...           0.2     Iris-setosa\n",
              "5      6            5.4  ...           0.4     Iris-setosa\n",
              "6      7            4.6  ...           0.3     Iris-setosa\n",
              "7      8            5.0  ...           0.2     Iris-setosa\n",
              "8      9            4.4  ...           0.2     Iris-setosa\n",
              "9     10            4.9  ...           0.1     Iris-setosa\n",
              "10    11            5.4  ...           0.2     Iris-setosa\n",
              "11    12            4.8  ...           0.2     Iris-setosa\n",
              "12    13            4.8  ...           0.1     Iris-setosa\n",
              "13    14            4.3  ...           0.1     Iris-setosa\n",
              "14    15            5.8  ...           0.2     Iris-setosa\n",
              "15    16            5.7  ...           0.4     Iris-setosa\n",
              "16    17            5.4  ...           0.4     Iris-setosa\n",
              "17    18            5.1  ...           0.3     Iris-setosa\n",
              "18    19            5.7  ...           0.3     Iris-setosa\n",
              "19    20            5.1  ...           0.3     Iris-setosa\n",
              "20    21            5.4  ...           0.2     Iris-setosa\n",
              "21    22            5.1  ...           0.4     Iris-setosa\n",
              "22    23            4.6  ...           0.2     Iris-setosa\n",
              "23    24            5.1  ...           0.5     Iris-setosa\n",
              "24    25            4.8  ...           0.2     Iris-setosa\n",
              "25    26            5.0  ...           0.2     Iris-setosa\n",
              "26    27            5.0  ...           0.4     Iris-setosa\n",
              "27    28            5.2  ...           0.2     Iris-setosa\n",
              "28    29            5.2  ...           0.2     Iris-setosa\n",
              "29    30            4.7  ...           0.2     Iris-setosa\n",
              "..   ...            ...  ...           ...             ...\n",
              "120  121            6.9  ...           2.3  Iris-virginica\n",
              "121  122            5.6  ...           2.0  Iris-virginica\n",
              "122  123            7.7  ...           2.0  Iris-virginica\n",
              "123  124            6.3  ...           1.8  Iris-virginica\n",
              "124  125            6.7  ...           2.1  Iris-virginica\n",
              "125  126            7.2  ...           1.8  Iris-virginica\n",
              "126  127            6.2  ...           1.8  Iris-virginica\n",
              "127  128            6.1  ...           1.8  Iris-virginica\n",
              "128  129            6.4  ...           2.1  Iris-virginica\n",
              "129  130            7.2  ...           1.6  Iris-virginica\n",
              "130  131            7.4  ...           1.9  Iris-virginica\n",
              "131  132            7.9  ...           2.0  Iris-virginica\n",
              "132  133            6.4  ...           2.2  Iris-virginica\n",
              "133  134            6.3  ...           1.5  Iris-virginica\n",
              "134  135            6.1  ...           1.4  Iris-virginica\n",
              "135  136            7.7  ...           2.3  Iris-virginica\n",
              "136  137            6.3  ...           2.4  Iris-virginica\n",
              "137  138            6.4  ...           1.8  Iris-virginica\n",
              "138  139            6.0  ...           1.8  Iris-virginica\n",
              "139  140            6.9  ...           2.1  Iris-virginica\n",
              "140  141            6.7  ...           2.4  Iris-virginica\n",
              "141  142            6.9  ...           2.3  Iris-virginica\n",
              "142  143            5.8  ...           1.9  Iris-virginica\n",
              "143  144            6.8  ...           2.3  Iris-virginica\n",
              "144  145            6.7  ...           2.5  Iris-virginica\n",
              "145  146            6.7  ...           2.3  Iris-virginica\n",
              "146  147            6.3  ...           1.9  Iris-virginica\n",
              "147  148            6.5  ...           2.0  Iris-virginica\n",
              "148  149            6.2  ...           2.3  Iris-virginica\n",
              "149  150            5.9  ...           1.8  Iris-virginica\n",
              "\n",
              "[150 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjAr-2ceOw7n",
        "colab_type": "text"
      },
      "source": [
        "### Splitting the data into feature set and target set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPOSy6LVOw7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split into Feature and Target set\n",
        "\n",
        "X= iris.drop(columns=['Id','Species'])\n",
        "y=iris['Species']\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiV4iIFSOw7r",
        "colab_type": "text"
      },
      "source": [
        "### Target set has different categories. So, Label encode them. And convert into one-hot vectors using get_dummies in pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLTKvnAzOw7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encoding Target variable\n",
        "\n",
        "from sklearn import preprocessing\n",
        "y = preprocessing.LabelEncoder().fit_transform(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IYyecqfmn_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=pd.get_dummies(y).values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6nG3EZEOw7v",
        "colab_type": "text"
      },
      "source": [
        "### Divide the dataset into Training and test (70:30)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpYb8v4lOw7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split into Train and Test set in the ratio of 7:3\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.30, random_state=123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iId0yN8Hslkl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X=train_X.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMrHlA6Tv3Le",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c7d68c2b-952d-4e14-c95f-4d9f80b47765"
      },
      "source": [
        "train_X"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.8, 2.8, 5.1, 2.4],\n",
              "       [6.3, 3.4, 5.6, 2.4],\n",
              "       [5.5, 2.3, 4. , 1.3],\n",
              "       [5.1, 3.8, 1.5, 0.3],\n",
              "       [4.4, 3. , 1.3, 0.2],\n",
              "       [6.5, 3.2, 5.1, 2. ],\n",
              "       [5.1, 3.3, 1.7, 0.5],\n",
              "       [4.9, 3.1, 1.5, 0.1],\n",
              "       [6.7, 3.1, 4.7, 1.5],\n",
              "       [6.1, 3. , 4.6, 1.4],\n",
              "       [5.5, 2.5, 4. , 1.3],\n",
              "       [5.7, 2.6, 3.5, 1. ],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [6.7, 3.1, 4.4, 1.4],\n",
              "       [6.4, 3.2, 5.3, 2.3],\n",
              "       [4.5, 2.3, 1.3, 0.3],\n",
              "       [6.7, 3.3, 5.7, 2.1],\n",
              "       [5.7, 3. , 4.2, 1.2],\n",
              "       [5.1, 3.7, 1.5, 0.4],\n",
              "       [4.8, 3.4, 1.6, 0.2],\n",
              "       [6.3, 2.9, 5.6, 1.8],\n",
              "       [6.4, 2.9, 4.3, 1.3],\n",
              "       [7.7, 2.8, 6.7, 2. ],\n",
              "       [7.7, 2.6, 6.9, 2.3],\n",
              "       [5.1, 3.8, 1.9, 0.4],\n",
              "       [6.4, 3.2, 4.5, 1.5],\n",
              "       [5.5, 2.4, 3.7, 1. ],\n",
              "       [5.9, 3. , 5.1, 1.8],\n",
              "       [4.8, 3. , 1.4, 0.1],\n",
              "       [7.2, 3. , 5.8, 1.6],\n",
              "       [6.3, 3.3, 4.7, 1.6],\n",
              "       [7. , 3.2, 4.7, 1.4],\n",
              "       [5. , 3. , 1.6, 0.2],\n",
              "       [6.4, 2.8, 5.6, 2.1],\n",
              "       [6.3, 2.5, 5. , 1.9],\n",
              "       [5. , 3.5, 1.6, 0.6],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [6.1, 2.8, 4. , 1.3],\n",
              "       [6.5, 2.8, 4.6, 1.5],\n",
              "       [6.3, 3.3, 6. , 2.5],\n",
              "       [5.8, 4. , 1.2, 0.2],\n",
              "       [4.6, 3.4, 1.4, 0.3],\n",
              "       [5.5, 2.4, 3.8, 1.1],\n",
              "       [5. , 3.4, 1.6, 0.4],\n",
              "       [5.9, 3.2, 4.8, 1.8],\n",
              "       [6.9, 3.1, 5.4, 2.1],\n",
              "       [4.8, 3.1, 1.6, 0.2],\n",
              "       [6.7, 2.5, 5.8, 1.8],\n",
              "       [5.7, 4.4, 1.5, 0.4],\n",
              "       [5.7, 3.8, 1.7, 0.3],\n",
              "       [6.7, 3. , 5. , 1.7],\n",
              "       [4.6, 3.6, 1. , 0.2],\n",
              "       [5.4, 3.7, 1.5, 0.2],\n",
              "       [6.6, 2.9, 4.6, 1.3],\n",
              "       [7.3, 2.9, 6.3, 1.8],\n",
              "       [6.6, 3. , 4.4, 1.4],\n",
              "       [5.6, 2.9, 3.6, 1.3],\n",
              "       [5.6, 2.5, 3.9, 1.1],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.5, 1.3, 0.3],\n",
              "       [6.8, 2.8, 4.8, 1.4],\n",
              "       [6.1, 2.6, 5.6, 1.4],\n",
              "       [4.9, 3.1, 1.5, 0.1],\n",
              "       [5.2, 3.5, 1.5, 0.2],\n",
              "       [5.6, 2.7, 4.2, 1.3],\n",
              "       [6. , 3.4, 4.5, 1.6],\n",
              "       [6.2, 2.9, 4.3, 1.3],\n",
              "       [7.1, 3. , 5.9, 2.1],\n",
              "       [6.9, 3.1, 4.9, 1.5],\n",
              "       [5.8, 2.6, 4. , 1.2],\n",
              "       [5.7, 2.8, 4.1, 1.3],\n",
              "       [7.6, 3. , 6.6, 2.1],\n",
              "       [5. , 3.4, 1.5, 0.2],\n",
              "       [5.3, 3.7, 1.5, 0.2],\n",
              "       [5.9, 3. , 4.2, 1.5],\n",
              "       [6.9, 3.2, 5.7, 2.3],\n",
              "       [6.4, 3.1, 5.5, 1.8],\n",
              "       [7.2, 3.2, 6. , 1.8],\n",
              "       [6.5, 3. , 5.2, 2. ],\n",
              "       [5.1, 3.4, 1.5, 0.2],\n",
              "       [5.4, 3. , 4.5, 1.5],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [5.8, 2.7, 4.1, 1. ],\n",
              "       [5.7, 2.8, 4.5, 1.3],\n",
              "       [5. , 3.3, 1.4, 0.2],\n",
              "       [6.2, 2.2, 4.5, 1.5],\n",
              "       [6.7, 3.1, 5.6, 2.4],\n",
              "       [6. , 2.9, 4.5, 1.5],\n",
              "       [6.7, 3.3, 5.7, 2.5],\n",
              "       [6.4, 2.7, 5.3, 1.9],\n",
              "       [5.2, 4.1, 1.5, 0.1],\n",
              "       [6.1, 2.8, 4.7, 1.2],\n",
              "       [4.6, 3.2, 1.4, 0.2],\n",
              "       [6.2, 3.4, 5.4, 2.3],\n",
              "       [5.7, 2.5, 5. , 2. ],\n",
              "       [5.7, 2.9, 4.2, 1.3],\n",
              "       [4.9, 2.4, 3.3, 1. ],\n",
              "       [6.3, 2.7, 4.9, 1.8],\n",
              "       [4.9, 2.5, 4.5, 1.7],\n",
              "       [6. , 2.7, 5.1, 1.6],\n",
              "       [5.1, 3.5, 1.4, 0.3],\n",
              "       [5.1, 2.5, 3. , 1.1],\n",
              "       [5.6, 3. , 4.5, 1.5],\n",
              "       [6.2, 2.8, 4.8, 1.8],\n",
              "       [7.2, 3.6, 6.1, 2.5]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-6MFVCCv6_s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "e919c58d-3bc1-43b3-9574-19d2d4bdf8ff"
      },
      "source": [
        "test_X=test_X.values\n",
        "test_X"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.3, 2.5, 4.9, 1.5],\n",
              "       [6.8, 3. , 5.5, 2.1],\n",
              "       [6.4, 2.8, 5.6, 2.2],\n",
              "       [5.6, 3. , 4.1, 1.3],\n",
              "       [4.9, 3.1, 1.5, 0.1],\n",
              "       [6. , 3. , 4.8, 1.8],\n",
              "       [6.3, 2.3, 4.4, 1.3],\n",
              "       [4.4, 3.2, 1.3, 0.2],\n",
              "       [4.4, 2.9, 1.4, 0.2],\n",
              "       [5.5, 2.6, 4.4, 1.2],\n",
              "       [6.9, 3.1, 5.1, 2.3],\n",
              "       [5.5, 4.2, 1.4, 0.2],\n",
              "       [5.2, 2.7, 3.9, 1.4],\n",
              "       [6.5, 3. , 5.5, 1.8],\n",
              "       [7.7, 3. , 6.1, 2.3],\n",
              "       [6.5, 3. , 5.8, 2.2],\n",
              "       [5.5, 3.5, 1.3, 0.2],\n",
              "       [4.3, 3. , 1.1, 0.1],\n",
              "       [6.1, 2.9, 4.7, 1.4],\n",
              "       [4.8, 3. , 1.4, 0.3],\n",
              "       [5.2, 3.4, 1.4, 0.2],\n",
              "       [6.3, 2.8, 5.1, 1.5],\n",
              "       [4.8, 3.4, 1.9, 0.2],\n",
              "       [6.1, 3. , 4.9, 1.8],\n",
              "       [5.1, 3.8, 1.6, 0.2],\n",
              "       [5.4, 3.4, 1.7, 0.2],\n",
              "       [5.4, 3.4, 1.5, 0.4],\n",
              "       [5.6, 2.8, 4.9, 2. ],\n",
              "       [7.7, 3.8, 6.7, 2.2],\n",
              "       [5. , 3.6, 1.4, 0.2],\n",
              "       [7.4, 2.8, 6.1, 1.9],\n",
              "       [6. , 2.2, 5. , 1.5],\n",
              "       [4.7, 3.2, 1.6, 0.2],\n",
              "       [5.1, 3.5, 1.4, 0.2],\n",
              "       [6. , 2.2, 4. , 1. ],\n",
              "       [5. , 2.3, 3.3, 1. ],\n",
              "       [7.9, 3.8, 6.4, 2. ],\n",
              "       [5.4, 3.9, 1.7, 0.4],\n",
              "       [5.4, 3.9, 1.3, 0.4],\n",
              "       [5.8, 2.7, 3.9, 1.2],\n",
              "       [5. , 2. , 3.5, 1. ],\n",
              "       [5. , 3.2, 1.2, 0.2],\n",
              "       [6.8, 3.2, 5.9, 2.3],\n",
              "       [6.7, 3. , 5.2, 2.3],\n",
              "       [5.8, 2.7, 5.1, 1.9]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uvjZyWSv6BZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEEZZwErsliz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09345caf-d608-44ee-b42e-2dc99b373cb0"
      },
      "source": [
        "train_y.shape"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(105,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ml76geO2Ow7z",
        "colab_type": "text"
      },
      "source": [
        "### Model\n",
        "Build the model with following layers: <br>\n",
        "1. First dense layer with 10 neurons with input shape 4 (according to the feature set) <br>\n",
        "2. Second Dense layer with 8 neurons <br>\n",
        "3. Output layer with 3 neurons with softmax activation (output layer, 3 neurons as we have 3 classes) <br>\n",
        "4. Use SGD and categorical_crossentropy loss "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kR6PERakOw70",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model Building\n",
        "#Initialize Sequential Graph (model)\n",
        "model1 = tf.keras.Sequential()\n",
        "\n",
        "#Normalize the data\n",
        "model1.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "#Add Dense layer for prediction - Keras declares weights and bias automatically\n",
        "model1.add(tf.keras.layers.Dense(10, activation='sigmoid'))\n",
        "\n",
        "#Add 2nd Dense layer with 8 neurons\n",
        "model1.add(tf.keras.layers.Dense(8, activation='sigmoid'))\n",
        "\n",
        "#Output layer with 3 neurons\n",
        "model1.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
        "\n",
        "# Model compilation with SGD and Cross-Entropy\n",
        "model1.compile(optimizer='sgd', loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNpWgUzZOw73",
        "colab_type": "text"
      },
      "source": [
        "### Fitting the model and predicting "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gxMy9vHOw74",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cba23efa-3b9e-403c-9d1b-d5bcabec502a"
      },
      "source": [
        "# Model Fit and Predict\n",
        "\n",
        "model1.fit(train_X,train_y,validation_data=(test_X, test_y), epochs=100, batch_size=10)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 105 samples, validate on 45 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1/100\n",
            "105/105 [==============================] - 0s 4ms/sample - loss: 1.1461 - acc: 0.0667 - val_loss: 1.0940 - val_acc: 0.3778\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 0s 201us/sample - loss: 1.1370 - acc: 0.1619 - val_loss: 1.0957 - val_acc: 0.3778\n",
            "Epoch 3/100\n",
            "105/105 [==============================] - 0s 218us/sample - loss: 1.1313 - acc: 0.1048 - val_loss: 1.0979 - val_acc: 0.3778\n",
            "Epoch 4/100\n",
            "105/105 [==============================] - 0s 201us/sample - loss: 1.1253 - acc: 0.0857 - val_loss: 1.1002 - val_acc: 0.3778\n",
            "Epoch 5/100\n",
            "105/105 [==============================] - 0s 200us/sample - loss: 1.1211 - acc: 0.1524 - val_loss: 1.1027 - val_acc: 0.3778\n",
            "Epoch 6/100\n",
            "105/105 [==============================] - 0s 200us/sample - loss: 1.1170 - acc: 0.1238 - val_loss: 1.1052 - val_acc: 0.3778\n",
            "Epoch 7/100\n",
            "105/105 [==============================] - 0s 192us/sample - loss: 1.1133 - acc: 0.1619 - val_loss: 1.1071 - val_acc: 0.3778\n",
            "Epoch 8/100\n",
            "105/105 [==============================] - 0s 199us/sample - loss: 1.1102 - acc: 0.1810 - val_loss: 1.1103 - val_acc: 0.3778\n",
            "Epoch 9/100\n",
            "105/105 [==============================] - 0s 217us/sample - loss: 1.1112 - acc: 0.4095 - val_loss: 1.1122 - val_acc: 0.3778\n",
            "Epoch 10/100\n",
            "105/105 [==============================] - 0s 235us/sample - loss: 1.1071 - acc: 0.3619 - val_loss: 1.1133 - val_acc: 0.4000\n",
            "Epoch 11/100\n",
            "105/105 [==============================] - 0s 222us/sample - loss: 1.1058 - acc: 0.4190 - val_loss: 1.1153 - val_acc: 0.4667\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 0s 208us/sample - loss: 1.1033 - acc: 0.3810 - val_loss: 1.1157 - val_acc: 0.4444\n",
            "Epoch 13/100\n",
            "105/105 [==============================] - 0s 202us/sample - loss: 1.1013 - acc: 0.3810 - val_loss: 1.1155 - val_acc: 0.3111\n",
            "Epoch 14/100\n",
            "105/105 [==============================] - 0s 212us/sample - loss: 1.1020 - acc: 0.3810 - val_loss: 1.1146 - val_acc: 0.2667\n",
            "Epoch 15/100\n",
            "105/105 [==============================] - 0s 215us/sample - loss: 1.0981 - acc: 0.3810 - val_loss: 1.1151 - val_acc: 0.2667\n",
            "Epoch 16/100\n",
            "105/105 [==============================] - 0s 207us/sample - loss: 1.0984 - acc: 0.3810 - val_loss: 1.1149 - val_acc: 0.2667\n",
            "Epoch 17/100\n",
            "105/105 [==============================] - 0s 227us/sample - loss: 1.0972 - acc: 0.3810 - val_loss: 1.1142 - val_acc: 0.2667\n",
            "Epoch 18/100\n",
            "105/105 [==============================] - 0s 202us/sample - loss: 1.0951 - acc: 0.3810 - val_loss: 1.1132 - val_acc: 0.2444\n",
            "Epoch 19/100\n",
            "105/105 [==============================] - 0s 219us/sample - loss: 1.0944 - acc: 0.3810 - val_loss: 1.1119 - val_acc: 0.2444\n",
            "Epoch 20/100\n",
            "105/105 [==============================] - 0s 212us/sample - loss: 1.0927 - acc: 0.3810 - val_loss: 1.1108 - val_acc: 0.2444\n",
            "Epoch 21/100\n",
            "105/105 [==============================] - 0s 233us/sample - loss: 1.0924 - acc: 0.3810 - val_loss: 1.1100 - val_acc: 0.2222\n",
            "Epoch 22/100\n",
            "105/105 [==============================] - 0s 230us/sample - loss: 1.0907 - acc: 0.3810 - val_loss: 1.1104 - val_acc: 0.2222\n",
            "Epoch 23/100\n",
            "105/105 [==============================] - 0s 212us/sample - loss: 1.0902 - acc: 0.3810 - val_loss: 1.1087 - val_acc: 0.2222\n",
            "Epoch 24/100\n",
            "105/105 [==============================] - 0s 202us/sample - loss: 1.0876 - acc: 0.3810 - val_loss: 1.1073 - val_acc: 0.2222\n",
            "Epoch 25/100\n",
            "105/105 [==============================] - 0s 200us/sample - loss: 1.0891 - acc: 0.3810 - val_loss: 1.1069 - val_acc: 0.2222\n",
            "Epoch 26/100\n",
            "105/105 [==============================] - 0s 224us/sample - loss: 1.0858 - acc: 0.3810 - val_loss: 1.1063 - val_acc: 0.2222\n",
            "Epoch 27/100\n",
            "105/105 [==============================] - 0s 248us/sample - loss: 1.0862 - acc: 0.3810 - val_loss: 1.1061 - val_acc: 0.2222\n",
            "Epoch 28/100\n",
            "105/105 [==============================] - 0s 203us/sample - loss: 1.0841 - acc: 0.3810 - val_loss: 1.1050 - val_acc: 0.2222\n",
            "Epoch 29/100\n",
            "105/105 [==============================] - 0s 204us/sample - loss: 1.0837 - acc: 0.3810 - val_loss: 1.1051 - val_acc: 0.2222\n",
            "Epoch 30/100\n",
            "105/105 [==============================] - 0s 205us/sample - loss: 1.0812 - acc: 0.3810 - val_loss: 1.1038 - val_acc: 0.2222\n",
            "Epoch 31/100\n",
            "105/105 [==============================] - 0s 207us/sample - loss: 1.0825 - acc: 0.3810 - val_loss: 1.1023 - val_acc: 0.2222\n",
            "Epoch 32/100\n",
            "105/105 [==============================] - 0s 187us/sample - loss: 1.0805 - acc: 0.3810 - val_loss: 1.1012 - val_acc: 0.2222\n",
            "Epoch 33/100\n",
            "105/105 [==============================] - 0s 191us/sample - loss: 1.0814 - acc: 0.3810 - val_loss: 1.0999 - val_acc: 0.2222\n",
            "Epoch 34/100\n",
            "105/105 [==============================] - 0s 192us/sample - loss: 1.0784 - acc: 0.3810 - val_loss: 1.0984 - val_acc: 0.2222\n",
            "Epoch 35/100\n",
            "105/105 [==============================] - 0s 188us/sample - loss: 1.0784 - acc: 0.3810 - val_loss: 1.0980 - val_acc: 0.2222\n",
            "Epoch 36/100\n",
            "105/105 [==============================] - 0s 196us/sample - loss: 1.0779 - acc: 0.3810 - val_loss: 1.0961 - val_acc: 0.2222\n",
            "Epoch 37/100\n",
            "105/105 [==============================] - 0s 224us/sample - loss: 1.0755 - acc: 0.3810 - val_loss: 1.0967 - val_acc: 0.2222\n",
            "Epoch 38/100\n",
            "105/105 [==============================] - 0s 208us/sample - loss: 1.0735 - acc: 0.3810 - val_loss: 1.0970 - val_acc: 0.2222\n",
            "Epoch 39/100\n",
            "105/105 [==============================] - 0s 197us/sample - loss: 1.0748 - acc: 0.3810 - val_loss: 1.0932 - val_acc: 0.2222\n",
            "Epoch 40/100\n",
            "105/105 [==============================] - 0s 186us/sample - loss: 1.0703 - acc: 0.3810 - val_loss: 1.0932 - val_acc: 0.2222\n",
            "Epoch 41/100\n",
            "105/105 [==============================] - 0s 187us/sample - loss: 1.0708 - acc: 0.3810 - val_loss: 1.0915 - val_acc: 0.2222\n",
            "Epoch 42/100\n",
            "105/105 [==============================] - 0s 203us/sample - loss: 1.0718 - acc: 0.3810 - val_loss: 1.0893 - val_acc: 0.2222\n",
            "Epoch 43/100\n",
            "105/105 [==============================] - 0s 208us/sample - loss: 1.0709 - acc: 0.3810 - val_loss: 1.0868 - val_acc: 0.2222\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 0s 207us/sample - loss: 1.0699 - acc: 0.3810 - val_loss: 1.0841 - val_acc: 0.2222\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 0s 190us/sample - loss: 1.0647 - acc: 0.3810 - val_loss: 1.0823 - val_acc: 0.2222\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 0s 191us/sample - loss: 1.0632 - acc: 0.3810 - val_loss: 1.0814 - val_acc: 0.2222\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 0s 215us/sample - loss: 1.0640 - acc: 0.3810 - val_loss: 1.0785 - val_acc: 0.2667\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 0s 207us/sample - loss: 1.0629 - acc: 0.3810 - val_loss: 1.0786 - val_acc: 0.2222\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 0s 208us/sample - loss: 1.0613 - acc: 0.3810 - val_loss: 1.0773 - val_acc: 0.2222\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 0s 233us/sample - loss: 1.0603 - acc: 0.3810 - val_loss: 1.0767 - val_acc: 0.2222\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 0s 249us/sample - loss: 1.0605 - acc: 0.3810 - val_loss: 1.0752 - val_acc: 0.2444\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 0s 241us/sample - loss: 1.0625 - acc: 0.3810 - val_loss: 1.0761 - val_acc: 0.2222\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 0s 205us/sample - loss: 1.0560 - acc: 0.3810 - val_loss: 1.0727 - val_acc: 0.2444\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 0s 221us/sample - loss: 1.0541 - acc: 0.3810 - val_loss: 1.0693 - val_acc: 0.2667\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 0s 288us/sample - loss: 1.0550 - acc: 0.3810 - val_loss: 1.0678 - val_acc: 0.2667\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 0s 207us/sample - loss: 1.0574 - acc: 0.3810 - val_loss: 1.0662 - val_acc: 0.2667\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 0s 184us/sample - loss: 1.0532 - acc: 0.3905 - val_loss: 1.0649 - val_acc: 0.2667\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 0s 195us/sample - loss: 1.0530 - acc: 0.3810 - val_loss: 1.0626 - val_acc: 0.2667\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 0s 197us/sample - loss: 1.0499 - acc: 0.3810 - val_loss: 1.0612 - val_acc: 0.2667\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 0s 197us/sample - loss: 1.0492 - acc: 0.3810 - val_loss: 1.0595 - val_acc: 0.2667\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 0s 190us/sample - loss: 1.0454 - acc: 0.3810 - val_loss: 1.0567 - val_acc: 0.2667\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 0s 193us/sample - loss: 1.0462 - acc: 0.3810 - val_loss: 1.0544 - val_acc: 0.2667\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 0s 185us/sample - loss: 1.0446 - acc: 0.3810 - val_loss: 1.0512 - val_acc: 0.2667\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 0s 204us/sample - loss: 1.0500 - acc: 0.4000 - val_loss: 1.0495 - val_acc: 0.2667\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 0s 190us/sample - loss: 1.0440 - acc: 0.4000 - val_loss: 1.0481 - val_acc: 0.2667\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 0s 214us/sample - loss: 1.0402 - acc: 0.4190 - val_loss: 1.0461 - val_acc: 0.2667\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 0s 202us/sample - loss: 1.0385 - acc: 0.4190 - val_loss: 1.0442 - val_acc: 0.2667\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 0s 204us/sample - loss: 1.0386 - acc: 0.4190 - val_loss: 1.0434 - val_acc: 0.2667\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 0s 211us/sample - loss: 1.0335 - acc: 0.4286 - val_loss: 1.0419 - val_acc: 0.2667\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 0s 203us/sample - loss: 1.0323 - acc: 0.4095 - val_loss: 1.0415 - val_acc: 0.2667\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 0s 203us/sample - loss: 1.0359 - acc: 0.4095 - val_loss: 1.0389 - val_acc: 0.2667\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 0s 216us/sample - loss: 1.0343 - acc: 0.4476 - val_loss: 1.0359 - val_acc: 0.2667\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 0s 215us/sample - loss: 1.0291 - acc: 0.4571 - val_loss: 1.0345 - val_acc: 0.2889\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 0s 202us/sample - loss: 1.0320 - acc: 0.4190 - val_loss: 1.0313 - val_acc: 0.4222\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 0s 209us/sample - loss: 1.0297 - acc: 0.4286 - val_loss: 1.0290 - val_acc: 0.4444\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 0s 215us/sample - loss: 1.0245 - acc: 0.4952 - val_loss: 1.0282 - val_acc: 0.4444\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 0s 211us/sample - loss: 1.0289 - acc: 0.4476 - val_loss: 1.0258 - val_acc: 0.4889\n",
            "Epoch 78/100\n",
            "105/105 [==============================] - 0s 206us/sample - loss: 1.0233 - acc: 0.4857 - val_loss: 1.0250 - val_acc: 0.4444\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 0s 203us/sample - loss: 1.0243 - acc: 0.4286 - val_loss: 1.0215 - val_acc: 0.5333\n",
            "Epoch 80/100\n",
            "105/105 [==============================] - 0s 202us/sample - loss: 1.0218 - acc: 0.5524 - val_loss: 1.0208 - val_acc: 0.4444\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 0s 195us/sample - loss: 1.0181 - acc: 0.5333 - val_loss: 1.0187 - val_acc: 0.5556\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 0s 202us/sample - loss: 1.0229 - acc: 0.5143 - val_loss: 1.0179 - val_acc: 0.5333\n",
            "Epoch 83/100\n",
            "105/105 [==============================] - 0s 198us/sample - loss: 1.0153 - acc: 0.4952 - val_loss: 1.0160 - val_acc: 0.5333\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 0s 200us/sample - loss: 1.0134 - acc: 0.5143 - val_loss: 1.0145 - val_acc: 0.6000\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 0s 192us/sample - loss: 1.0208 - acc: 0.5333 - val_loss: 1.0112 - val_acc: 0.6222\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 0s 208us/sample - loss: 1.0120 - acc: 0.5429 - val_loss: 1.0094 - val_acc: 0.6222\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 0s 179us/sample - loss: 1.0107 - acc: 0.5429 - val_loss: 1.0059 - val_acc: 0.6667\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 0s 186us/sample - loss: 1.0086 - acc: 0.5524 - val_loss: 1.0034 - val_acc: 0.6667\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 0s 188us/sample - loss: 1.0092 - acc: 0.5714 - val_loss: 1.0013 - val_acc: 0.6667\n",
            "Epoch 90/100\n",
            "105/105 [==============================] - 0s 205us/sample - loss: 1.0047 - acc: 0.6476 - val_loss: 0.9989 - val_acc: 0.6667\n",
            "Epoch 91/100\n",
            "105/105 [==============================] - 0s 197us/sample - loss: 1.0016 - acc: 0.6095 - val_loss: 0.9969 - val_acc: 0.6667\n",
            "Epoch 92/100\n",
            "105/105 [==============================] - 0s 186us/sample - loss: 1.0049 - acc: 0.5810 - val_loss: 0.9953 - val_acc: 0.6667\n",
            "Epoch 93/100\n",
            "105/105 [==============================] - 0s 187us/sample - loss: 1.0032 - acc: 0.5714 - val_loss: 0.9920 - val_acc: 0.6667\n",
            "Epoch 94/100\n",
            "105/105 [==============================] - 0s 201us/sample - loss: 0.9995 - acc: 0.6571 - val_loss: 0.9899 - val_acc: 0.6667\n",
            "Epoch 95/100\n",
            "105/105 [==============================] - 0s 198us/sample - loss: 0.9974 - acc: 0.6381 - val_loss: 0.9886 - val_acc: 0.6667\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 0s 224us/sample - loss: 0.9972 - acc: 0.6190 - val_loss: 0.9851 - val_acc: 0.6667\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 0s 202us/sample - loss: 0.9904 - acc: 0.7238 - val_loss: 0.9840 - val_acc: 0.6667\n",
            "Epoch 98/100\n",
            "105/105 [==============================] - 0s 229us/sample - loss: 0.9879 - acc: 0.6762 - val_loss: 0.9811 - val_acc: 0.6667\n",
            "Epoch 99/100\n",
            "105/105 [==============================] - 0s 202us/sample - loss: 0.9860 - acc: 0.6857 - val_loss: 0.9804 - val_acc: 0.6667\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 0s 196us/sample - loss: 0.9915 - acc: 0.6095 - val_loss: 0.9770 - val_acc: 0.6667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5d0e25a390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTnDMFKTOw77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aT3oXsHOw7-",
        "colab_type": "text"
      },
      "source": [
        "### Report Accuracy of the predicted values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d6SkiyjOw7_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f2d19056-d32c-420c-c0c6-801705754610"
      },
      "source": [
        "# Accuracy of the model\n",
        "\n",
        "model1.evaluate(test_X,test_y)\n",
        "\n",
        "# 67% - Accuracy"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45/45 [==============================] - 0s 2ms/sample - loss: 0.9770 - acc: 0.6667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9769932574696011, 0.6666667]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    }
  ]
}